[{"authors":["admin"],"categories":null,"content":"Jelmer Poelstra started at the MCIC (Molecular and Cellular Imaging Center) in June 2020, where he provides bioinformatics support and education. His background is in evolutionary and population genetics, and most of his research has focused on understanding speciation using genomic approaches.\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1603299924,"objectID":"2525497d367e79493fd32b198b28f040","permalink":"https://biodash.github.io/authors/admin/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/authors/admin/","section":"authors","summary":"Jelmer Poelstra started at the MCIC (Molecular and Cellular Imaging Center) in June 2020, where he provides bioinformatics support and education. His background is in evolutionary and population genetics, and most of his research has focused on understanding speciation using genomic approaches.","tags":null,"title":"Jelmer Poelstra","type":"authors"},{"authors":["jessica-cooperstone"],"categories":null,"content":"Jessica Cooperstone is an Assistant Professor in Horticulture and Crop Science, and Food Science and Technology at The Ohio State University working at the intersection of plant science and human nutrition.\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1603214439,"objectID":"da60494872ddaf739115b5da033f1fed","permalink":"https://biodash.github.io/authors/jessica-cooperstone/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/authors/jessica-cooperstone/","section":"authors","summary":"Jessica Cooperstone is an Assistant Professor in Horticulture and Crop Science, and Food Science and Technology at The Ohio State University working at the intersection of plant science and human nutrition.","tags":null,"title":"Jessica Cooperstone","type":"authors"},{"authors":["michael-broe"],"categories":null,"content":"Michael Broe is a Bioinformatics Research Scientist at the Department of Evolution, Ecology, and Organismal Biology.\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1603299924,"objectID":"f515857d0961e2ded569db22cc57c70c","permalink":"https://biodash.github.io/authors/michael-broe/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/authors/michael-broe/","section":"authors","summary":"Michael Broe is a Bioinformatics Research Scientist at the Department of Evolution, Ecology, and Organismal Biology.","tags":null,"title":"Michael Broe","type":"authors"},{"authors":["mike-sovic"],"categories":null,"content":"Mike Sovic is a Bioinformatics Research Scientist at CAPS, the Center for Applied Plant Sciences.\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1603299924,"objectID":"e25a3ca217243530f65efb3cd930207b","permalink":"https://biodash.github.io/authors/mike-sovic/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/authors/mike-sovic/","section":"authors","summary":"Mike Sovic is a Bioinformatics Research Scientist at CAPS, the Center for Applied Plant Sciences.","tags":null,"title":"Mike Sovic","type":"authors"},{"authors":["stephen-opiyo"],"categories":null,"content":"Stephen Opiyo is a bioinformatics and biostatistics research scientist at MCIC Columbus.\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1603299924,"objectID":"9c82e356b8ac88d63b60055c202796b4","permalink":"https://biodash.github.io/authors/stephen-opiyo/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/authors/stephen-opiyo/","section":"authors","summary":"Stephen Opiyo is a bioinformatics and biostatistics research scientist at MCIC Columbus.","tags":null,"title":"Stephen Opiyo","type":"authors"},{"authors":["Mike Sovic"],"categories":null,"content":"\n New To Code Club?   First, check out the Code Club Computer Setup instructions, which also has some pointers that might be helpful if you\u0026rsquo;re new to R or RStudio.\n  Please open RStudio before Code Club to test things out \u0026ndash; if you run into issues, join the Zoom call early and we\u0026rsquo;ll troubleshoot.\n   Session Goals  Differentiate between different types of joins\u0026hellip;  inner_join() full_join() left_join() right_join()   Use a join function to add new variables to the birds dataset Keep practicing with dplyr core verbs from last week, esp\u0026hellip;  select() filter()   Answer the question \u0026ldquo;What Ohio bird species have the longest and shortest average lifespans?\u0026rdquo;.   Intro: Merging/Joining Datasets Sometimes you don\u0026rsquo;t have all your data in the same place. For example, maybe you have multiple Excel sheets for a project - each storing a different type of data for the same set of samples. Or maybe you\u0026rsquo;re interested in analyzing various metrics for US states and are getting the data from different places online - economic data from one database, climate data from another, and so on. As part of the process of data wrangling, it\u0026rsquo;s often useful to merge the separate datasets together according to a variable they share, possibly \u0026ldquo;SampleID\u0026rdquo; or \u0026ldquo;State Name\u0026rdquo; for the two above examples, respectively. R offers several ways to do this, but we\u0026rsquo;ll focus here on the set of *_join() functions available in dplyr. They include\u0026hellip;\n inner_join() full_join() left_join() right_join() semi_join() anti_join()  Check out the \u0026lsquo;Combine Data Sets\u0026rsquo; section of this cheat sheet for a brief look at these functions.\nYou can also get more details here, or, as with any R function, by accessing the function\u0026rsquo;s documentation inside R with the \u0026lsquo;?\u0026rsquo;. For example, type ?inner_join at your R prompt and hit Enter. (Make sure the package the function comes from is loaded first! In this case, you need dplyr, which is loaded as part of tidyverse.)\n Examples Below we\u0026rsquo;ll go through a few examples of joins. You\u0026rsquo;re welcome to follow along and run this code on your own, but it\u0026rsquo;s not necessary - the exercises in the breakout rooms are independent of these examples and will give you a chance to try these things out on your own.\nIf you want to follow along, you can find the code here\n Load Packages Since the _join() functions come from the dplyr package, which is part of tidyverse, I\u0026rsquo;ll load that first\u0026hellip;\n#this assumes you've already installed tidyverse library(tidyverse) ## ── Attaching packages ─────────────────────────────────────── tidyverse 1.3.0 ── ## ✓ ggplot2 3.3.2 ✓ purrr 0.3.4 ## ✓ tibble 3.0.4 ✓ dplyr 1.0.0 ## ✓ tidyr 1.1.0 ✓ stringr 1.4.0 ## ✓ readr 1.3.1 ✓ forcats 0.5.0 ## ── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ── ## x dplyr::filter() masks stats::filter() ## x dplyr::lag() masks stats::lag()  The National Health and Nutrition Examination Survey (NHANES) dataset contains survey data obtained annually from ~5,000 individuals on a variety of health and lifestyle-related metrics. A subset of the data are available as an R package - install and load it\u0026hellip;\ninstall.packages(\u0026quot;NHANES\u0026quot;) ## Loading required package: NHANES library(NHANES)  Now preview the dataset\u0026hellip;\nglimpse(NHANES) ## Rows: 10,000 ## Columns: 76 ## $ ID \u0026lt;int\u0026gt; 51624, 51624, 51624, 51625, 51630, 51638, 51646, 516… ## $ SurveyYr \u0026lt;fct\u0026gt; 2009_10, 2009_10, 2009_10, 2009_10, 2009_10, 2009_10… ## $ Gender \u0026lt;fct\u0026gt; male, male, male, male, female, male, male, female, … ## $ Age \u0026lt;int\u0026gt; 34, 34, 34, 4, 49, 9, 8, 45, 45, 45, 66, 58, 54, 10,… ## $ AgeDecade \u0026lt;fct\u0026gt; 30-39, 30-39, 30-39, 0-9, 40-49, 0-9, 0-9, 4… ## $ AgeMonths \u0026lt;int\u0026gt; 409, 409, 409, 49, 596, 115, 101, 541, 541, 541, 795… ## $ Race1 \u0026lt;fct\u0026gt; White, White, White, Other, White, White, White, Whi… ## $ Race3 \u0026lt;fct\u0026gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, … ## $ Education \u0026lt;fct\u0026gt; High School, High School, High School, NA, Some Coll… ## $ MaritalStatus \u0026lt;fct\u0026gt; Married, Married, Married, NA, LivePartner, NA, NA, … ## $ HHIncome \u0026lt;fct\u0026gt; 25000-34999, 25000-34999, 25000-34999, 20000-24999, … ## $ HHIncomeMid \u0026lt;int\u0026gt; 30000, 30000, 30000, 22500, 40000, 87500, 60000, 875… ## $ Poverty \u0026lt;dbl\u0026gt; 1.36, 1.36, 1.36, 1.07, 1.91, 1.84, 2.33, 5.00, 5.00… ## $ HomeRooms \u0026lt;int\u0026gt; 6, 6, 6, 9, 5, 6, 7, 6, 6, 6, 5, 10, 6, 10, 10, 4, 3… ## $ HomeOwn \u0026lt;fct\u0026gt; Own, Own, Own, Own, Rent, Rent, Own, Own, Own, Own, … ## $ Work \u0026lt;fct\u0026gt; NotWorking, NotWorking, NotWorking, NA, NotWorking, … ## $ Weight \u0026lt;dbl\u0026gt; 87.4, 87.4, 87.4, 17.0, 86.7, 29.8, 35.2, 75.7, 75.7… ## $ Length \u0026lt;dbl\u0026gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, … ## $ HeadCirc \u0026lt;dbl\u0026gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, … ## $ Height \u0026lt;dbl\u0026gt; 164.7, 164.7, 164.7, 105.4, 168.4, 133.1, 130.6, 166… ## $ BMI \u0026lt;dbl\u0026gt; 32.22, 32.22, 32.22, 15.30, 30.57, 16.82, 20.64, 27.… ## $ BMICatUnder20yrs \u0026lt;fct\u0026gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, … ## $ BMI_WHO \u0026lt;fct\u0026gt; 30.0_plus, 30.0_plus, 30.0_plus, 12.0_18.5, 30.0_plu… ## $ Pulse \u0026lt;int\u0026gt; 70, 70, 70, NA, 86, 82, 72, 62, 62, 62, 60, 62, 76, … ## $ BPSysAve \u0026lt;int\u0026gt; 113, 113, 113, NA, 112, 86, 107, 118, 118, 118, 111,… ## $ BPDiaAve \u0026lt;int\u0026gt; 85, 85, 85, NA, 75, 47, 37, 64, 64, 64, 63, 74, 85, … ## $ BPSys1 \u0026lt;int\u0026gt; 114, 114, 114, NA, 118, 84, 114, 106, 106, 106, 124,… ## $ BPDia1 \u0026lt;int\u0026gt; 88, 88, 88, NA, 82, 50, 46, 62, 62, 62, 64, 76, 86, … ## $ BPSys2 \u0026lt;int\u0026gt; 114, 114, 114, NA, 108, 84, 108, 118, 118, 118, 108,… ## $ BPDia2 \u0026lt;int\u0026gt; 88, 88, 88, NA, 74, 50, 36, 68, 68, 68, 62, 72, 88, … ## $ BPSys3 \u0026lt;int\u0026gt; 112, 112, 112, NA, 116, 88, 106, 118, 118, 118, 114,… ## $ BPDia3 \u0026lt;int\u0026gt; 82, 82, 82, NA, 76, 44, 38, 60, 60, 60, 64, 76, 82, … ## $ Testosterone \u0026lt;dbl\u0026gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, … ## $ DirectChol \u0026lt;dbl\u0026gt; 1.29, 1.29, 1.29, NA, 1.16, 1.34, 1.55, 2.12, 2.12, … ## $ TotChol \u0026lt;dbl\u0026gt; 3.49, 3.49, 3.49, NA, 6.70, 4.86, 4.09, 5.82, 5.82, … ## $ UrineVol1 \u0026lt;int\u0026gt; 352, 352, 352, NA, 77, 123, 238, 106, 106, 106, 113,… ## $ UrineFlow1 \u0026lt;dbl\u0026gt; NA, NA, NA, NA, 0.094, 1.538, 1.322, 1.116, 1.116, 1… ## $ UrineVol2 \u0026lt;int\u0026gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, … ## $ UrineFlow2 \u0026lt;dbl\u0026gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, … ## $ Diabetes \u0026lt;fct\u0026gt; No, No, No, No, No, No, No, No, No, No, No, No, No, … ## $ DiabetesAge \u0026lt;int\u0026gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, … ## $ HealthGen \u0026lt;fct\u0026gt; Good, Good, Good, NA, Good, NA, NA, Vgood, Vgood, Vg… ## $ DaysPhysHlthBad \u0026lt;int\u0026gt; 0, 0, 0, NA, 0, NA, NA, 0, 0, 0, 10, 0, 4, NA, NA, 0… ## $ DaysMentHlthBad \u0026lt;int\u0026gt; 15, 15, 15, NA, 10, NA, NA, 3, 3, 3, 0, 0, 0, NA, NA… ## $ LittleInterest \u0026lt;fct\u0026gt; Most, Most, Most, NA, Several, NA, NA, None, None, N… ## $ Depressed \u0026lt;fct\u0026gt; Several, Several, Several, NA, Several, NA, NA, None… ## $ nPregnancies \u0026lt;int\u0026gt; NA, NA, NA, NA, 2, NA, NA, 1, 1, 1, NA, NA, NA, NA, … ## $ nBabies \u0026lt;int\u0026gt; NA, NA, NA, NA, 2, NA, NA, NA, NA, NA, NA, NA, NA, N… ## $ Age1stBaby \u0026lt;int\u0026gt; NA, NA, NA, NA, 27, NA, NA, NA, NA, NA, NA, NA, NA, … ## $ SleepHrsNight \u0026lt;int\u0026gt; 4, 4, 4, NA, 8, NA, NA, 8, 8, 8, 7, 5, 4, NA, 5, 7, … ## $ SleepTrouble \u0026lt;fct\u0026gt; Yes, Yes, Yes, NA, Yes, NA, NA, No, No, No, No, No, … ## $ PhysActive \u0026lt;fct\u0026gt; No, No, No, NA, No, NA, NA, Yes, Yes, Yes, Yes, Yes,… ## $ PhysActiveDays \u0026lt;int\u0026gt; NA, NA, NA, NA, NA, NA, NA, 5, 5, 5, 7, 5, 1, NA, 2,… ## $ TVHrsDay \u0026lt;fct\u0026gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, … ## $ CompHrsDay \u0026lt;fct\u0026gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, … ## $ TVHrsDayChild \u0026lt;int\u0026gt; NA, NA, NA, 4, NA, 5, 1, NA, NA, NA, NA, NA, NA, 4, … ## $ CompHrsDayChild \u0026lt;int\u0026gt; NA, NA, NA, 1, NA, 0, 6, NA, NA, NA, NA, NA, NA, 3, … ## $ Alcohol12PlusYr \u0026lt;fct\u0026gt; Yes, Yes, Yes, NA, Yes, NA, NA, Yes, Yes, Yes, Yes, … ## $ AlcoholDay \u0026lt;int\u0026gt; NA, NA, NA, NA, 2, NA, NA, 3, 3, 3, 1, 2, 6, NA, NA,… ## $ AlcoholYear \u0026lt;int\u0026gt; 0, 0, 0, NA, 20, NA, NA, 52, 52, 52, 100, 104, 364, … ## $ SmokeNow \u0026lt;fct\u0026gt; No, No, No, NA, Yes, NA, NA, NA, NA, NA, No, NA, NA,… ## $ Smoke100 \u0026lt;fct\u0026gt; Yes, Yes, Yes, NA, Yes, NA, NA, No, No, No, Yes, No,… ## $ Smoke100n \u0026lt;fct\u0026gt; Smoker, Smoker, Smoker, NA, Smoker, NA, NA, Non-Smok… ## $ SmokeAge \u0026lt;int\u0026gt; 18, 18, 18, NA, 38, NA, NA, NA, NA, NA, 13, NA, NA, … ## $ Marijuana \u0026lt;fct\u0026gt; Yes, Yes, Yes, NA, Yes, NA, NA, Yes, Yes, Yes, NA, Y… ## $ AgeFirstMarij \u0026lt;int\u0026gt; 17, 17, 17, NA, 18, NA, NA, 13, 13, 13, NA, 19, 15, … ## $ RegularMarij \u0026lt;fct\u0026gt; No, No, No, NA, No, NA, NA, No, No, No, NA, Yes, Yes… ## $ AgeRegMarij \u0026lt;int\u0026gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, 20, 15, … ## $ HardDrugs \u0026lt;fct\u0026gt; Yes, Yes, Yes, NA, Yes, NA, NA, No, No, No, No, Yes,… ## $ SexEver \u0026lt;fct\u0026gt; Yes, Yes, Yes, NA, Yes, NA, NA, Yes, Yes, Yes, Yes, … ## $ SexAge \u0026lt;int\u0026gt; 16, 16, 16, NA, 12, NA, NA, 13, 13, 13, 17, 22, 12, … ## $ SexNumPartnLife \u0026lt;int\u0026gt; 8, 8, 8, NA, 10, NA, NA, 20, 20, 20, 15, 7, 100, NA,… ## $ SexNumPartYear \u0026lt;int\u0026gt; 1, 1, 1, NA, 1, NA, NA, 0, 0, 0, NA, 1, 1, NA, NA, 1… ## $ SameSex \u0026lt;fct\u0026gt; No, No, No, NA, Yes, NA, NA, Yes, Yes, Yes, No, No, … ## $ SexOrientation \u0026lt;fct\u0026gt; Heterosexual, Heterosexual, Heterosexual, NA, Hetero… ## $ PregnantNow \u0026lt;fct\u0026gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, …  To try out merging/joining, we\u0026rsquo;ll create two separate data frames by pulling out some variables from this NHANES dataset. One will contain demographic variables, and the other with have some physical measurements. Then we\u0026rsquo;ll join them back together. Let\u0026rsquo;s create the two sub-datasets first\u0026hellip;\n#Filter out rows with data from 2009-2010 and Age \u0026gt; 5, select a subset (4) of the variables, then get rid of all duplicate rows. Assign the output to object 'dem_data'. dem_data \u0026lt;- NHANES %\u0026gt;% filter(SurveyYr == \u0026quot;2009_10\u0026quot;) %\u0026gt;% filter(Age \u0026gt; 5) %\u0026gt;% select(ID, Gender, Age, Education) %\u0026gt;% distinct() #similar as above, but with a different filter and selecting different variables. Save as 'phys_data' phys_data \u0026lt;- NHANES %\u0026gt;% filter(SurveyYr == \u0026quot;2009_10\u0026quot;) %\u0026gt;% filter(Height \u0026lt; 180) %\u0026gt;% select(ID, Height, BMI, Pulse) %\u0026gt;% distinct()  Now explore them a bit\u0026hellip;\n#view the first 6 rows of each - note the shared ID column head(dem_data) ## # A tibble: 6 x 4 ## ID Gender Age Education ## \u0026lt;int\u0026gt; \u0026lt;fct\u0026gt; \u0026lt;int\u0026gt; \u0026lt;fct\u0026gt; ## 1 51624 male 34 High School ## 2 51630 female 49 Some College ## 3 51638 male 9 \u0026lt;NA\u0026gt; ## 4 51646 male 8 \u0026lt;NA\u0026gt; ## 5 51647 female 45 College Grad ## 6 51654 male 66 Some College head(phys_data) ## # A tibble: 6 x 4 ## ID Height BMI Pulse ## \u0026lt;int\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;int\u0026gt; ## 1 51624 165. 32.2 70 ## 2 51625 105. 15.3 NA ## 3 51630 168. 30.6 86 ## 4 51638 133. 16.8 82 ## 5 51646 131. 20.6 72 ## 6 51647 167. 27.2 62 #preview in another way - note the different numbers of observations (rows) glimpse(dem_data) ## Rows: 3,217 ## Columns: 4 ## $ ID \u0026lt;int\u0026gt; 51624, 51630, 51638, 51646, 51647, 51654, 51656, 51657, 516… ## $ Gender \u0026lt;fct\u0026gt; male, female, male, male, female, male, male, male, female,… ## $ Age \u0026lt;int\u0026gt; 34, 49, 9, 8, 45, 66, 58, 54, 10, 58, 50, 9, 33, 60, 16, 56… ## $ Education \u0026lt;fct\u0026gt; High School, Some College, NA, NA, College Grad, Some Colle… glimpse(phys_data) ## Rows: 3,021 ## Columns: 4 ## $ ID \u0026lt;int\u0026gt; 51624, 51625, 51630, 51638, 51646, 51647, 51654, 51657, 51659,… ## $ Height \u0026lt;dbl\u0026gt; 164.7, 105.4, 168.4, 133.1, 130.6, 166.7, 169.5, 169.4, 141.8,… ## $ BMI \u0026lt;dbl\u0026gt; 32.22, 15.30, 30.57, 16.82, 20.64, 27.24, 23.67, 26.03, 19.20,… ## $ Pulse \u0026lt;int\u0026gt; 70, NA, 86, 82, 72, 62, 60, 76, 80, 94, 74, 92, 84, 76, 64, 70…  Let\u0026rsquo;s use the shared ID column to join the two datasets together. We\u0026rsquo;ll do this in 4 different ways to compare different types of joins: inner_join(), left_join(), right_join(), and full_join(). Pay attention to the number of rows in the joined dataset each time and how it relates to the number of rows in each of the two individual datasets.\nThe basic structure of the dplyr *_join functions is\u0026hellip;\n*_join(dataframe \u0026lsquo;x\u0026rsquo;, dataframe \u0026lsquo;y\u0026rsquo;, by = shared column name)\n 1 - inner_join() #perform an inner join join_inner \u0026lt;- inner_join(dem_data, phys_data, by = \u0026quot;ID\u0026quot;) #preview the new object head(join_inner) ## # A tibble: 6 x 7 ## ID Gender Age Education Height BMI Pulse ## \u0026lt;int\u0026gt; \u0026lt;fct\u0026gt; \u0026lt;int\u0026gt; \u0026lt;fct\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;int\u0026gt; ## 1 51624 male 34 High School 165. 32.2 70 ## 2 51630 female 49 Some College 168. 30.6 86 ## 3 51638 male 9 \u0026lt;NA\u0026gt; 133. 16.8 82 ## 4 51646 male 8 \u0026lt;NA\u0026gt; 131. 20.6 72 ## 5 51647 female 45 College Grad 167. 27.2 62 ## 6 51654 male 66 Some College 170. 23.7 60 #get dimensions dim(join_inner) ## [1] 2806 7  2 - left_join() #perform a left join join_left \u0026lt;- left_join(dem_data, phys_data, by = \u0026quot;ID\u0026quot;) #preview the new object head(join_left) ## # A tibble: 6 x 7 ## ID Gender Age Education Height BMI Pulse ## \u0026lt;int\u0026gt; \u0026lt;fct\u0026gt; \u0026lt;int\u0026gt; \u0026lt;fct\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;int\u0026gt; ## 1 51624 male 34 High School 165. 32.2 70 ## 2 51630 female 49 Some College 168. 30.6 86 ## 3 51638 male 9 \u0026lt;NA\u0026gt; 133. 16.8 82 ## 4 51646 male 8 \u0026lt;NA\u0026gt; 131. 20.6 72 ## 5 51647 female 45 College Grad 167. 27.2 62 ## 6 51654 male 66 Some College 170. 23.7 60 #get dimensions dim(join_left) ## [1] 3217 7  3 - right_join() #perform a right join join_right \u0026lt;- right_join(dem_data, phys_data, by = \u0026quot;ID\u0026quot;) #preview the new object head(join_right) ## # A tibble: 6 x 7 ## ID Gender Age Education Height BMI Pulse ## \u0026lt;int\u0026gt; \u0026lt;fct\u0026gt; \u0026lt;int\u0026gt; \u0026lt;fct\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;int\u0026gt; ## 1 51624 male 34 High School 165. 32.2 70 ## 2 51630 female 49 Some College 168. 30.6 86 ## 3 51638 male 9 \u0026lt;NA\u0026gt; 133. 16.8 82 ## 4 51646 male 8 \u0026lt;NA\u0026gt; 131. 20.6 72 ## 5 51647 female 45 College Grad 167. 27.2 62 ## 6 51654 male 66 Some College 170. 23.7 60 #get dimensions dim(join_right) ## [1] 3021 7  4 - full_join() #perform a full join join_full \u0026lt;- full_join(dem_data, phys_data, by = \u0026quot;ID\u0026quot;) #preview the new object head(join_full) ## # A tibble: 6 x 7 ## ID Gender Age Education Height BMI Pulse ## \u0026lt;int\u0026gt; \u0026lt;fct\u0026gt; \u0026lt;int\u0026gt; \u0026lt;fct\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;int\u0026gt; ## 1 51624 male 34 High School 165. 32.2 70 ## 2 51630 female 49 Some College 168. 30.6 86 ## 3 51638 male 9 \u0026lt;NA\u0026gt; 133. 16.8 82 ## 4 51646 male 8 \u0026lt;NA\u0026gt; 131. 20.6 72 ## 5 51647 female 45 College Grad 167. 27.2 62 ## 6 51654 male 66 Some College 170. 23.7 60 #get dimensions dim(join_full) ## [1] 3432 7   Breakout rooms We\u0026rsquo;re going to add to our backyard birds dataset. I found a dataset that has life history data for a large number of species (birds and others). We\u0026rsquo;ll use species names to merge some of these life history variables in to the occurrence data we already have.\nIf you\u0026rsquo;re new and haven\u0026rsquo;t yet gotten the backyard bird dataset, get it first by running the code below. Otherwise, you can skip this step\u0026hellip;\n# create a directory called data that contains a subdirectory called birds dir.create('data/birds/', recursive = TRUE) # set the location of the file birds_file_url \u0026lt;- 'https://raw.githubusercontent.com/biodash/biodash.github.io/master/assets/data/birds/backyard-birds_Ohio.tsv' # set the path for the downloaded file birds_file \u0026lt;- 'data/birds/backyard-birds_Ohio.tsv' # download download.file(url = birds_file_url, destfile = birds_file)  Now (everybody), read in the bird data for this session\u0026hellip;\nbirds_file \u0026lt;- 'data/birds/backyard-birds_Ohio.tsv' birds \u0026lt;- read_tsv(birds_file) ## Parsed with column specification: ## cols( ## class = col_character(), ## order = col_character(), ## family = col_character(), ## genus = col_character(), ## species = col_character(), ## locality = col_character(), ## stateProvince = col_character(), ## decimalLatitude = col_double(), ## decimalLongitude = col_double(), ## eventDate = col_datetime(format = \u0026quot;\u0026quot;), ## species_en = col_character(), ## range = col_character() ## )  Exercise 1 Reduce the backyard bird dataset and keep just the following columns: species, locality, stateProvince, eventDate, species_en\n  Hints (click here)  \nUse select() to pull out the columns you want.    Solution (click here)  birds \u0026lt;- birds %\u0026gt;% select(species, locality, stateProvince, eventDate, species_en)    Exercise 2 Check to make sure things look right - how many columns does the birds dataset now have?\n  Hints (click here)  \nUse the dim() function. Or the ncol() function. Or glimpse(). Or head(). Or str(). Or even summary(). There\u0026rsquo;s lots of ways to do this. \n  Solution (click here)  dim(birds) ## [1] 311441 5    Exercise 3 Now download and read in the new life history dataset (tab separated) available at https://github.com/biodash/biodash.github.io/raw/master/assets/data/birds/esa_life_history_data_cc.tsv. Then explore it a bit - how many rows and columns are there?\n  Hints (click here)  \nUse the download.file() function like we did previously for the bird dataset. You\u0026rsquo;ll need to define the arguments \u0026lsquo;url\u0026rsquo; and \u0026lsquo;destfile\u0026rsquo; inside the parentheses. You can put the file anywhere you want, but I\u0026rsquo;d suggest in the same directory as the bird file we got, so, for example, the destination file could be \u0026ldquo;data/birds/life_history_data.tsv\u0026rdquo;.    Solution (click here)  #download the file from online and save it as a '.tsv' file (since it's tab delimited) download.file(url = \u0026quot;https://github.com/biodash/biodash.github.io/raw/master/assets/data/birds/esa_life_history_data_cc.tsv\u0026quot;, destfile = \u0026quot;data/birds/life_history_data.tsv\u0026quot;) #read the data in to R as an object named 'life_hist' life_hist \u0026lt;- read_tsv(file = \u0026quot;data/birds/life_history_data.tsv\u0026quot;) #preview the data glimpse(life_hist)    Exercise 4 This new dataset contains life history data for more than just birds. What Classes of organisms are represented in the \u0026lsquo;Class\u0026rsquo; variable?\n  Hints (click here)  \nTry using a combination of the select() and distinct() functions to pull out the column you\u0026rsquo;re interested in, and then to get the distinct values, respectively. \n  Solutions (click here)  life_hist %\u0026gt;% select(class) %\u0026gt;% distinct() ## # A tibble: 3 x 1 ## class ## \u0026lt;chr\u0026gt; ## 1 Aves ## 2 Mammalia ## 3 Reptilia    Exercise 5 Reduce the life history dataset down to keep just the rows for Class Aves and the columns species, adult_body_mass_g, adult_svl_cm, longevity_y, litter_or_clutch_size_n\n  Hints (click here)  Use filter() along with an appropriate logical expression to keep the rows we want. Use select() to get the desired columns. \n  Solutions (click here)  # pull out target rows and columns life_hist_aves \u0026lt;- life_hist %\u0026gt;% filter(class == \u0026quot;Aves\u0026quot;) %\u0026gt;% select(species, adult_body_mass_g, adult_svl_cm, longevity_y, litter_or_clutch_size_n)    Exercise 6 Preview each dataset again, just to make sure you\u0026rsquo;re clear about what\u0026rsquo;s in each one. Are there any columns that are shared between the two?\n  Hints (click here)  Several options here - glimpse() or head() are good to try.    Solutions (click here)  glimpse(birds) ## Rows: 311,441 ## Columns: 5 ## $ species \u0026lt;chr\u0026gt; \u0026quot;Cyanocitta cristata\u0026quot;, \u0026quot;Cyanocitta cristata\u0026quot;, \u0026quot;Cyanocit… ## $ locality \u0026lt;chr\u0026gt; \u0026quot;44805 Ashland\u0026quot;, \u0026quot;45244 Cincinnati\u0026quot;, \u0026quot;44132 Euclid\u0026quot;, \u0026quot;4… ## $ stateProvince \u0026lt;chr\u0026gt; \u0026quot;Ohio\u0026quot;, \u0026quot;Ohio\u0026quot;, \u0026quot;Ohio\u0026quot;, \u0026quot;Ohio\u0026quot;, \u0026quot;Ohio\u0026quot;, \u0026quot;Ohio\u0026quot;, \u0026quot;Ohio\u0026quot;,… ## $ eventDate \u0026lt;dttm\u0026gt; 2007-02-16, 2007-02-17, 2007-02-17, 2007-02-19, 2007-0… ## $ species_en \u0026lt;chr\u0026gt; \u0026quot;Blue Jay\u0026quot;, \u0026quot;Blue Jay\u0026quot;, \u0026quot;Blue Jay\u0026quot;, \u0026quot;Blue Jay\u0026quot;, \u0026quot;Blue J… glimpse(life_hist) ## Rows: 21,322 ## Columns: 5 ## $ species \u0026lt;chr\u0026gt; \u0026quot;Accipiter albogularis\u0026quot;, \u0026quot;Accipiter badius\u0026quot;… ## $ adult_body_mass_g \u0026lt;dbl\u0026gt; 251.500, 140.000, 345.000, 142.000, 203.500… ## $ adult_svl_cm \u0026lt;dbl\u0026gt; NA, 30.00, 39.50, NA, 33.50, NA, 39.50, 29.… ## $ longevity_y \u0026lt;dbl\u0026gt; NA, NA, NA, NA, NA, NA, NA, 12.58333, NA, 1… ## $ litter_or_clutch_size_n \u0026lt;dbl\u0026gt; NA, 3.250, 2.700, NA, 4.000, NA, 2.700, 4.2…    Exercise 7 Now lets join them together based on their shared variable. Not all species in the backyard bird (Ohio) dataset are included in the life history dataset. Likewise, there are life history data for many species that aren\u0026rsquo;t in the Ohio dataset. We want to keep all the Ohio observations, and merge in life history data for species where it\u0026rsquo;s availble, but we also don\u0026rsquo;t want to add in life history data for species that aren\u0026rsquo;t in the Ohio dataset. Choose an appropriate join function with those things in mind.\n  Hints (click here)  Try a left_join(), defining the Ohio backyard bird dataset as the \u0026lsquo;x\u0026rsquo; dataset in the join and the life history data as the \u0026lsquo;y\u0026rsquo; dataset. Get details on that function with ?left_join.    Solutions (click here)  joined_data \u0026lt;- left_join(x = birds, y = life_hist_aves, by = \u0026quot;species\u0026quot;)    Exercise 8 What are the longest- and shortest-living bird species in Ohio based on the data in the longevity_y column?\n  Hints (click here)  Try using select() to pull out just the columns species and longevity_y, then use distinct() to get the unique rows, then arrange() based on the longevity_y column. You might also find the dplyr function desc() helpful. Alternatively, you could try grouping by species, then use summarise() to get either the max, min, or mean value for longevity_y for each species (there\u0026rsquo;s just one value for each species, so all of those statistics give the same value in this case). Then sort (arrange) the resulting summarized data frame on the longevity value.\n\n\n  Solutions (click here)  #option 1 - shortest-lived birds joined_data %\u0026gt;% select(species, longevity_y) %\u0026gt;% distinct() %\u0026gt;% arrange(longevity_y) ## # A tibble: 171 x 2 ## species longevity_y ## \u0026lt;chr\u0026gt; \u0026lt;dbl\u0026gt; ## 1 Loxia leucoptera 4 ## 2 Spiza americana 4 ## 3 Certhia americana 4.6 ## 4 Acanthis hornemanni 4.6 ## 5 Tringa flavipes 4.75 ## 6 Podiceps grisegena 4.8 ## 7 Calcarius lapponicus 5 ## 8 Anthus rubescens 5.1 ## 9 Perdix perdix 5.17 ## 10 Regulus satrapa 5.32 ## # … with 161 more rows #option 1 - longest-lived birds joined_data %\u0026gt;% select(species, longevity_y) %\u0026gt;% distinct() %\u0026gt;% arrange(desc(longevity_y)) ## # A tibble: 171 x 2 ## species longevity_y ## \u0026lt;chr\u0026gt; \u0026lt;dbl\u0026gt; ## 1 Larus argentatus 33.4 ## 2 Larus glaucoides 33 ## 3 Larus thayeri 33 ## 4 Haliaeetus leucocephalus 33.0 ## 5 Larus fuscus 32.8 ## 6 Aquila chrysaetos 32 ## 7 Anas platyrhynchos 29 ## 8 Larus delawarensis 28.6 ## 9 Asio otus 27.8 ## 10 Cygnus olor 27.7 ## # … with 161 more rows #option 2 - shortest-lived birds joined_data %\u0026gt;% group_by(species) %\u0026gt;% summarise(longevity = max(longevity_y)) %\u0026gt;% arrange(longevity) ## `summarise()` ungrouping output (override with `.groups` argument) ## # A tibble: 171 x 2 ## species longevity ## \u0026lt;chr\u0026gt; \u0026lt;dbl\u0026gt; ## 1 Loxia leucoptera 4 ## 2 Spiza americana 4 ## 3 Acanthis hornemanni 4.6 ## 4 Certhia americana 4.6 ## 5 Tringa flavipes 4.75 ## 6 Podiceps grisegena 4.8 ## 7 Calcarius lapponicus 5 ## 8 Anthus rubescens 5.1 ## 9 Perdix perdix 5.17 ## 10 Regulus satrapa 5.32 ## # … with 161 more rows #option 2 - longest-lived birds joined_data %\u0026gt;% group_by(species) %\u0026gt;% summarise(longevity = max(longevity_y)) %\u0026gt;% arrange(desc(longevity)) ## `summarise()` ungrouping output (override with `.groups` argument) ## # A tibble: 171 x 2 ## species longevity ## \u0026lt;chr\u0026gt; \u0026lt;dbl\u0026gt; ## 1 Larus argentatus 33.4 ## 2 Larus glaucoides 33 ## 3 Larus thayeri 33 ## 4 Haliaeetus leucocephalus 33.0 ## 5 Larus fuscus 32.8 ## 6 Aquila chrysaetos 32 ## 7 Anas platyrhynchos 29 ## 8 Larus delawarensis 28.6 ## 9 Asio otus 27.8 ## 10 Cygnus olor 27.7 ## # … with 161 more rows    Bonus time! Bonus 1 What species in Ohio has the largest ratio of adult body mass to length (measured as snout vent length, or \u0026lsquo;adult_svl_cm\u0026rsquo;)?\n  Hints (click here)  Use mutate() to create a new variable containing the body mass divided by svl, then arrange the dataset using that new variable to get the species with the highest value.\n   Solutions (click here)  joined_data %\u0026gt;% mutate(ratio = adult_body_mass_g/adult_svl_cm) %\u0026gt;% select(species_en, ratio) %\u0026gt;% distinct() %\u0026gt;% arrange(desc(ratio)) ## # A tibble: 170 x 2 ## species_en ratio ## \u0026lt;chr\u0026gt; \u0026lt;dbl\u0026gt; ## 1 Mute Swan 71.8 ## 2 Wild Turkey 68.0 ## 3 Trumpeter Swan 64.9 ## 4 Bald Eagle 59.2 ## 5 Golden Eagle 56.2 ## 6 Canada Goose 48.3 ## 7 Tundra Swan 47.0 ## 8 Cackling Goose 44.4 ## 9 Snow Goose 35.1 ## 10 Snowy Owl 32.8 ## # … with 160 more rows    Bonus 2 The life history dataset we downloaded above is actually a modified version of the original file, which is located at \u0026lsquo;http://www.esapubs.org/archive/ecol/E096/269/Data_Files/Amniote_Database_Aug_2015.csv\u0026rsquo;\nTry starting with the original file and repeating what we did above - merging the variables species, adult_body_mass_g, adult_svl_cm, longevity_y, litter_or_clutch_size_n in to the original birds dataset. First, make sure to get it read in correctly. Then pay attention to the species column in the life history dataset - what needs to be done before a join/merge can be performed?\n  Hints (click here)  Pay attention to how missing data are coded in this dataset (it\u0026rsquo;s -999). Also, data are very sparse for some of the variables - in other words, they have lots of missing data. This seems to cause a problem with the read_csv function, as it only considers the first 1000 rows for the purpose of defining the class of each column. This can be a problem if all of the first 1000 rows are missing. Finally, it appears that even though this is a comma separated file (commas define the column breaks), there are a few instances where commas are used within a field. This happens in the \u0026lsquo;common name\u0026rsquo; column in a few cases where multiple common names are listed for a specific observation. This is one example of something that can become quite frustrating when trying to get data loaded in, and is worth keeping an eye out for. Fortunately, in our case, it only seems to happen for non-bird species in this dataset, which we filter out anyway, so it can be dealt with. However, if it had impacted any of the bird observations, I think fixing this might require a solution outside of R - possibly a command line approach.\n   Solutions (click here)  #download download.file(url = \u0026quot;http://www.esapubs.org/archive/ecol/E096/269/Data_Files/Amniote_Database_Aug_2015.csv\u0026quot;, destfile = \u0026quot;data/birds/orig_life_history.csv\u0026quot;) #read the data in to R as an object named 'full_life_hist' full_life_hist \u0026lt;- read_csv(\u0026quot;data/birds/orig_life_history.csv\u0026quot;, na = \u0026quot;-999\u0026quot;, col_types = cols(birth_or_hatching_svl_cm = col_double(), weaning_d = col_double(),gestation_d = col_double(), weaning_weight_g = col_double(), male_svl_cm = col_double(), female_svl_cm = col_double(), no_sex_svl_cm = col_double(), female_body_mass_at_maturity_g = col_double(), female_svl_at_maturity_cm = col_double())) #get the original version of the birds dataset birds \u0026lt;- read_tsv('data/birds/backyard-birds_Ohio.tsv') ## Parsed with column specification: ## cols( ## class = col_character(), ## order = col_character(), ## family = col_character(), ## genus = col_character(), ## species = col_character(), ## locality = col_character(), ## stateProvince = col_character(), ## decimalLatitude = col_double(), ## decimalLongitude = col_double(), ## eventDate = col_datetime(format = \u0026quot;\u0026quot;), ## species_en = col_character(), ## range = col_character() ## ) #subset each for the columns and rows we want life_hist_aves \u0026lt;- full_life_hist %\u0026gt;% filter(class == \u0026quot;Aves\u0026quot;) %\u0026gt;% select(species, adult_body_mass_g, adult_svl_cm, longevity_y, litter_or_clutch_size_n) birds \u0026lt;- birds %\u0026gt;% select(species, locality, stateProvince, eventDate, species_en) glimpse(birds) ## Rows: 311,441 ## Columns: 5 ## $ species \u0026lt;chr\u0026gt; \u0026quot;Cyanocitta cristata\u0026quot;, \u0026quot;Cyanocitta cristata\u0026quot;, \u0026quot;Cyanocit… ## $ locality \u0026lt;chr\u0026gt; \u0026quot;44805 Ashland\u0026quot;, \u0026quot;45244 Cincinnati\u0026quot;, \u0026quot;44132 Euclid\u0026quot;, \u0026quot;4… ## $ stateProvince \u0026lt;chr\u0026gt; \u0026quot;Ohio\u0026quot;, \u0026quot;Ohio\u0026quot;, \u0026quot;Ohio\u0026quot;, \u0026quot;Ohio\u0026quot;, \u0026quot;Ohio\u0026quot;, \u0026quot;Ohio\u0026quot;, \u0026quot;Ohio\u0026quot;,… ## $ eventDate \u0026lt;dttm\u0026gt; 2007-02-16, 2007-02-17, 2007-02-17, 2007-02-19, 2007-0… ## $ species_en \u0026lt;chr\u0026gt; \u0026quot;Blue Jay\u0026quot;, \u0026quot;Blue Jay\u0026quot;, \u0026quot;Blue Jay\u0026quot;, \u0026quot;Blue Jay\u0026quot;, \u0026quot;Blue J… glimpse(life_hist_aves) ## Rows: 9,802 ## Columns: 5 ## $ species \u0026lt;chr\u0026gt; \u0026quot;albogularis\u0026quot;, \u0026quot;badius\u0026quot;, \u0026quot;bicolor\u0026quot;, \u0026quot;brachyur… ## $ adult_body_mass_g \u0026lt;dbl\u0026gt; 251.500, 140.000, 345.000, 142.000, 203.500, … ## $ adult_svl_cm \u0026lt;dbl\u0026gt; NA, 30.00, 39.50, NA, 33.50, NA, 39.50, 29.00… ## $ longevity_y \u0026lt;dbl\u0026gt; NA, NA, NA, NA, NA, NA, NA, 12.58333, NA, 12.… ## $ litter_or_clutch_size_n \u0026lt;dbl\u0026gt; NA, 3.250, 2.700, NA, 4.000, NA, 2.700, 4.250… #notice the species column in the life history data doesn't include the genus name. Since the names don't match in the species column from each dataset, a join won't work. Add the genus variable in from the original life history data... life_hist_aves \u0026lt;- full_life_hist %\u0026gt;% filter(class == \u0026quot;Aves\u0026quot;) %\u0026gt;% select(genus, species, adult_body_mass_g, adult_svl_cm, longevity_y, litter_or_clutch_size_n) #now use mutate to replace the species column so it includes both the genus and species... life_hist_aves \u0026lt;- life_hist_aves %\u0026gt;% mutate(species = paste0(genus, \u0026quot; \u0026quot;, species)) %\u0026gt;% select(-genus) #preview again glimpse(birds) ## Rows: 311,441 ## Columns: 5 ## $ species \u0026lt;chr\u0026gt; \u0026quot;Cyanocitta cristata\u0026quot;, \u0026quot;Cyanocitta cristata\u0026quot;, \u0026quot;Cyanocit… ## $ locality \u0026lt;chr\u0026gt; \u0026quot;44805 Ashland\u0026quot;, \u0026quot;45244 Cincinnati\u0026quot;, \u0026quot;44132 Euclid\u0026quot;, \u0026quot;4… ## $ stateProvince \u0026lt;chr\u0026gt; \u0026quot;Ohio\u0026quot;, \u0026quot;Ohio\u0026quot;, \u0026quot;Ohio\u0026quot;, \u0026quot;Ohio\u0026quot;, \u0026quot;Ohio\u0026quot;, \u0026quot;Ohio\u0026quot;, \u0026quot;Ohio\u0026quot;,… ## $ eventDate \u0026lt;dttm\u0026gt; 2007-02-16, 2007-02-17, 2007-02-17, 2007-02-19, 2007-0… ## $ species_en \u0026lt;chr\u0026gt; \u0026quot;Blue Jay\u0026quot;, \u0026quot;Blue Jay\u0026quot;, \u0026quot;Blue Jay\u0026quot;, \u0026quot;Blue Jay\u0026quot;, \u0026quot;Blue J… glimpse(life_hist_aves) ## Rows: 9,802 ## Columns: 5 ## $ species \u0026lt;chr\u0026gt; \u0026quot;Accipiter albogularis\u0026quot;, \u0026quot;Accipiter badius\u0026quot;, … ## $ adult_body_mass_g \u0026lt;dbl\u0026gt; 251.500, 140.000, 345.000, 142.000, 203.500, … ## $ adult_svl_cm \u0026lt;dbl\u0026gt; NA, 30.00, 39.50, NA, 33.50, NA, 39.50, 29.00… ## $ longevity_y \u0026lt;dbl\u0026gt; NA, NA, NA, NA, NA, NA, NA, 12.58333, NA, 12.… ## $ litter_or_clutch_size_n \u0026lt;dbl\u0026gt; NA, 3.250, 2.700, NA, 4.000, NA, 2.700, 4.250… #now we can join joined_data \u0026lt;- left_join(birds, life_hist_aves, by = \u0026quot;species\u0026quot;)    \n","date":1607040000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1607118647,"objectID":"ac21371122a93dfd4641f808ad457bc3","permalink":"https://biodash.github.io/codeclub/s03_joining-datasets/","publishdate":"2020-12-04T00:00:00Z","relpermalink":"/codeclub/s03_joining-datasets/","section":"codeclub","summary":"In this session of Code Club, we'll explore some methods for combining datasets according to a shared variable, with primary focus on the ***_join()** set of functions from **dplyr**. We'll also keep practicing with some of the core dplyr verbs from last session.","tags":null,"title":"Session 3: Joining Datasets","type":"codeclub"},{"authors":["Jessica Cooperstone"],"categories":null,"content":"\n Prep homework Basic computer setup   If you didn\u0026rsquo;t already do this, please follow the Code Club Computer Setup instructions, which also has pointers for if you\u0026rsquo;re new to R or RStudio.\n  If you\u0026rsquo;re able to do so, please open RStudio a bit before Code Club starts \u0026ndash; and in case you run into issues, please join the Zoom call early and we\u0026rsquo;ll troubleshoot.\n  New to dplyr? If you\u0026rsquo;ve never used dplyr before (or even if you have), you may find this cheat sheet useful.\n Getting Started Want to download an R script with the content from today\u0026rsquo;s session? # directory for Code Club Session 2: dir.create(\"S02\") # directory for our script # (\"recursive\" to create two levels at once.) dir.create(\"S02/scripts/\") # save the url location for today's script todays_R_script \u0026lt;- 'https://raw.githubusercontent.com/biodash/biodash.github.io/master/content/codeclub/02_dplyr-core-verbs/2_Dplyr_one-table_verbs.R' # indicate the name of the new script file Session2_dplyr_core \u0026lt;- \"S02/scripts/Session2_script.R\" # go get that file!  download.file(url = todays_R_script, destfile = Session2_dplyr_core)    1 - What is data wrangling? It has been estimated that the process of getting your data into the appropriate formats takes about 80% of the total time of analysis. We will talk about formatting as tidy data (e.g., such that each column is a single variable, each row is a single observation, and each cell is a single value, you can learn more about tidy data here) in a future session of Code Club.\nThe package dplyr, as part of the tidyverse has a number of very helpful functions that will help you get your data into a format suitable for your analysis.\n What will we go over today\nThese five core dplyr() verbs will help you get wrangling.\n  select() - picks variables (i.e., columns) based on their names  filter() - picks observations (i.e., rows) based on their values  mutate() - makes new variables, keeps existing columns  arrange() - sorts rows based on values in columns  summarize() - reduces values down to a summary form     2 - Get ready to wrangle Let\u0026rsquo;s get set up and grab some data so that we can get familiar with these verbs\n You can do this locally, or at OSC. You can find instructions if you are having trouble here.  First load your libraries.\nlibrary(tidyverse) #\u0026gt; ── Attaching packages ─────────────────────────────────────── tidyverse 1.3.0 ── #\u0026gt; ✔ ggplot2 3.3.2 ✔ purrr  0.3.4 #\u0026gt; ✔ tibble  3.0.4 ✔ dplyr  1.0.2 #\u0026gt; ✔ tidyr  1.1.2 ✔ stringr 1.4.0 #\u0026gt; ✔ readr  1.4.0 ✔ forcats 0.5.0 #\u0026gt; ── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ── #\u0026gt; ✖ dplyr::filter() masks stats::filter() #\u0026gt; ✖ dplyr::lag() masks stats::lag()   Then let\u0026rsquo;s access the iris dataset that comes pre-loaded in base R. We will take that data frame and assign it to a new object called iris_data. Then we will look at our data.\niris_data \u0026lt;- iris # look at the first 6 rows, all columns head(iris_data) #\u0026gt; Sepal.Length Sepal.Width Petal.Length Petal.Width Species #\u0026gt; 1 5.1 3.5 1.4 0.2 setosa #\u0026gt; 2 4.9 3.0 1.4 0.2 setosa #\u0026gt; 3 4.7 3.2 1.3 0.2 setosa #\u0026gt; 4 4.6 3.1 1.5 0.2 setosa #\u0026gt; 5 5.0 3.6 1.4 0.2 setosa #\u0026gt; 6 5.4 3.9 1.7 0.4 setosa # check the structure of iris_data glimpse(iris_data) #\u0026gt; Rows: 150 #\u0026gt; Columns: 5 #\u0026gt; $ Sepal.Length \u0026lt;dbl\u0026gt; 5.1, 4.9, 4.7, 4.6, 5.0, 5.4, 4.6, 5.0, 4.4, 4.9, 5.4, 4… #\u0026gt; $ Sepal.Width \u0026lt;dbl\u0026gt; 3.5, 3.0, 3.2, 3.1, 3.6, 3.9, 3.4, 3.4, 2.9, 3.1, 3.7, 3… #\u0026gt; $ Petal.Length \u0026lt;dbl\u0026gt; 1.4, 1.4, 1.3, 1.5, 1.4, 1.7, 1.4, 1.5, 1.4, 1.5, 1.5, 1… #\u0026gt; $ Petal.Width \u0026lt;dbl\u0026gt; 0.2, 0.2, 0.2, 0.2, 0.2, 0.4, 0.3, 0.2, 0.2, 0.1, 0.2, 0… #\u0026gt; $ Species \u0026lt;fct\u0026gt; setosa, setosa, setosa, setosa, setosa, setosa, setosa, …   This dataset contains the measurements (in cm) of Sepal.Length, Sepal.Width, Petal.Length, and Petal.Width for three different Species of iris, setosa, versicolor, and virginica.\n 3 - Using select() select() allows you to pick certain columns to be included in your data frame.\nWe will create a dew data frame called iris_petals_species that includes the columns Species, Petal.Length and Petal.Width.\niris_petals_species \u0026lt;- iris_data %\u0026gt;% select(Species, Petal.Length, Petal.Width)   What does our new data frame look like?\nhead(iris_petals_species) #\u0026gt; Species Petal.Length Petal.Width #\u0026gt; 1 setosa 1.4 0.2 #\u0026gt; 2 setosa 1.4 0.2 #\u0026gt; 3 setosa 1.3 0.2 #\u0026gt; 4 setosa 1.5 0.2 #\u0026gt; 5 setosa 1.4 0.2 #\u0026gt; 6 setosa 1.7 0.4   Note - look what happened to the order of the columns!\nThis is not the only way to select columns.\nYou could also subset by indexing with the square brackets, but you can see how much more readable using select() is. It\u0026rsquo;s nice not to have to refer back to remember what column is which index.\niris_data_indexing \u0026lt;- iris_data[,3:5] head(iris_data_indexing) #\u0026gt; Petal.Length Petal.Width Species #\u0026gt; 1 1.4 0.2 setosa #\u0026gt; 2 1.4 0.2 setosa #\u0026gt; 3 1.3 0.2 setosa #\u0026gt; 4 1.5 0.2 setosa #\u0026gt; 5 1.4 0.2 setosa #\u0026gt; 6 1.7 0.4 setosa   iris_data_c \u0026lt;- iris_data[,c(\"Petal.Length\", \"Petal.Width\", \"Species\")] head(iris_data_c) #\u0026gt; Petal.Length Petal.Width Species #\u0026gt; 1 1.4 0.2 setosa #\u0026gt; 2 1.4 0.2 setosa #\u0026gt; 3 1.3 0.2 setosa #\u0026gt; 4 1.5 0.2 setosa #\u0026gt; 5 1.4 0.2 setosa #\u0026gt; 6 1.7 0.4 setosa     4 - Using filter()  Artwork by Allison Horst.   filter() allows you to pick certain observations (i.e, rows) based on their values to be included in your data frame.\nWe will create a new data frame that only includes information about the irises where their Species is setosa.\niris_setosa \u0026lt;- iris_data %\u0026gt;% filter(Species == \"setosa\")   Let\u0026rsquo;s check the dimensions of our data frame. Remember, our whole data set is 150 observations, and we are expecting 50 observations per Species.\ndim(iris_setosa) #\u0026gt; [1] 50 5    5 - Using mutate()  Artwork by Allison Horst.  mutate() allows you to make new variables, while keeping all your existing columns.\nLet\u0026rsquo;s make a new column that is the ratio of Sepal.Length/Sepal.Width\niris_sepal_length_to_width \u0026lt;- iris_data %\u0026gt;% mutate(Sepal.Length_div_Sepal.Width = Sepal.Length/Sepal.Width)   head(iris_sepal_length_to_width) #\u0026gt; Sepal.Length Sepal.Width Petal.Length Petal.Width Species #\u0026gt; 1 5.1 3.5 1.4 0.2 setosa #\u0026gt; 2 4.9 3.0 1.4 0.2 setosa #\u0026gt; 3 4.7 3.2 1.3 0.2 setosa #\u0026gt; 4 4.6 3.1 1.5 0.2 setosa #\u0026gt; 5 5.0 3.6 1.4 0.2 setosa #\u0026gt; 6 5.4 3.9 1.7 0.4 setosa #\u0026gt; Sepal.Length_div_Sepal.Width #\u0026gt; 1 1.457143 #\u0026gt; 2 1.633333 #\u0026gt; 3 1.468750 #\u0026gt; 4 1.483871 #\u0026gt; 5 1.388889 #\u0026gt; 6 1.384615   Note \u0026ndash; see the new column location\n 6 - Using arrange() Very often you will want to order your data frame by some values. To do this, you can use arrange().\nLet\u0026rsquo;s arrange the values in our iris_data by Sepal.Length.\niris_data_sort_Sepal.Length \u0026lt;- iris_data %\u0026gt;% arrange(Sepal.Length) head(iris_data_sort_Sepal.Length) #\u0026gt; Sepal.Length Sepal.Width Petal.Length Petal.Width Species #\u0026gt; 1 4.3 3.0 1.1 0.1 setosa #\u0026gt; 2 4.4 2.9 1.4 0.2 setosa #\u0026gt; 3 4.4 3.0 1.3 0.2 setosa #\u0026gt; 4 4.4 3.2 1.3 0.2 setosa #\u0026gt; 5 4.5 2.3 1.3 0.3 setosa #\u0026gt; 6 4.6 3.1 1.5 0.2 setosa   What if we want to arrange by Sepal.Length, but within Species? We can do that using the helper group_by().\niris_data %\u0026gt;% group_by(Species) %\u0026gt;% arrange(Sepal.Length) #\u0026gt; # A tibble: 150 x 5 #\u0026gt; # Groups: Species [3] #\u0026gt; Sepal.Length Sepal.Width Petal.Length Petal.Width Species #\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;fct\u0026gt;  #\u0026gt; 1 4.3 3 1.1 0.1 setosa  #\u0026gt; 2 4.4 2.9 1.4 0.2 setosa  #\u0026gt; 3 4.4 3 1.3 0.2 setosa  #\u0026gt; 4 4.4 3.2 1.3 0.2 setosa  #\u0026gt; 5 4.5 2.3 1.3 0.3 setosa  #\u0026gt; 6 4.6 3.1 1.5 0.2 setosa  #\u0026gt; 7 4.6 3.4 1.4 0.3 setosa  #\u0026gt; 8 4.6 3.6 1 0.2 setosa  #\u0026gt; 9 4.6 3.2 1.4 0.2 setosa  #\u0026gt; 10 4.7 3.2 1.3 0.2 setosa  #\u0026gt; # … with 140 more rows    7 - Using summarize() By using summarize(), you can create a new data frame that has the summary output you have requested.\nWe can calculate the mean Sepal.Length across our dataset.\niris_data %\u0026gt;% summarize(mean = mean(Sepal.Length)) #\u0026gt; mean #\u0026gt; 1 5.843333   What if we want to calculate means for each Species?\niris_data %\u0026gt;% group_by(Species) %\u0026gt;% summarize(mean = mean(Sepal.Length)) #\u0026gt; `summarise()` ungrouping output (override with `.groups` argument) #\u0026gt; # A tibble: 3 x 2 #\u0026gt; Species mean #\u0026gt; \u0026lt;fct\u0026gt; \u0026lt;dbl\u0026gt; #\u0026gt; 1 setosa 5.01 #\u0026gt; 2 versicolor 5.94 #\u0026gt; 3 virginica 6.59   We can integrate some helper functions into our code to simply get out a variety of outputs. We can use across() to apply our summary aross a set of columns. I really like this function.\niris_data %\u0026gt;% group_by(Species) %\u0026gt;% summarize(across(where(is.numeric), mean)) #\u0026gt; `summarise()` ungrouping output (override with `.groups` argument) #\u0026gt; # A tibble: 3 x 5 #\u0026gt; Species Sepal.Length Sepal.Width Petal.Length Petal.Width #\u0026gt; \u0026lt;fct\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; #\u0026gt; 1 setosa 5.01 3.43 1.46 0.246 #\u0026gt; 2 versicolor 5.94 2.77 4.26 1.33  #\u0026gt; 3 virginica 6.59 2.97 5.55 2.03   This can also be useful for counting observations per group. Here, how many iris observations do we have per Species?\niris_data %\u0026gt;% group_by(Species) %\u0026gt;% tally() #\u0026gt; # A tibble: 3 x 2 #\u0026gt; Species n #\u0026gt; \u0026lt;fct\u0026gt; \u0026lt;int\u0026gt; #\u0026gt; 1 setosa 50 #\u0026gt; 2 versicolor 50 #\u0026gt; 3 virginica 50 iris_data %\u0026gt;% count(Species) #\u0026gt; Species n #\u0026gt; 1 setosa 50 #\u0026gt; 2 versicolor 50 #\u0026gt; 3 virginica 50 iris_data %\u0026gt;% group_by(Species) %\u0026gt;% summarize(n = n()) #\u0026gt; `summarise()` ungrouping output (override with `.groups` argument) #\u0026gt; # A tibble: 3 x 2 #\u0026gt; Species n #\u0026gt; \u0026lt;fct\u0026gt; \u0026lt;int\u0026gt; #\u0026gt; 1 setosa 50 #\u0026gt; 2 versicolor 50 #\u0026gt; 3 virginica 50    8 - Breakout rooms! Read in data Now you try! We are going to use the Great Backyard Birds dataset we downloaded two weeks ago and you will apply the functions we have learned above to investigate this dataset.\nIf you weren\u0026rsquo;t here for Session 1, get the birds data set.\n# create a directory called S02 dir.create('S02') # within S02, create a directory called data, within, a directory called birds dir.create('data/birds/', recursive = TRUE)   Download the file from the internet.\n# set the location of the file birds_file_url \u0026lt;- 'https://raw.githubusercontent.com/biodash/biodash.github.io/master/assets/data/birds/backyard-birds_Ohio.tsv' # set the path for the downloaded file birds_file \u0026lt;- 'data/birds/backyard-birds_Ohio.tsv' # download  download.file(url = birds_file_url, destfile = birds_file)   If you were here for Session 1, join back in! Let\u0026rsquo;s read in our data.\nbirds_file \u0026lt;- 'data/birds/backyard-birds_Ohio.tsv' birds \u0026lt;- read_tsv(birds_file) #\u0026gt;  #\u0026gt; ── Column specification ──────────────────────────────────────────────────────── #\u0026gt; cols( #\u0026gt; class = col_character(), #\u0026gt; order = col_character(), #\u0026gt; family = col_character(), #\u0026gt; genus = col_character(), #\u0026gt; species = col_character(), #\u0026gt; locality = col_character(), #\u0026gt; stateProvince = col_character(), #\u0026gt; decimalLatitude = col_double(), #\u0026gt; decimalLongitude = col_double(), #\u0026gt; eventDate = col_datetime(format = \"\"), #\u0026gt; species_en = col_character(), #\u0026gt; range = col_character() #\u0026gt; )   Exercises Below you can find our breakout room exercises for today.\nExercise 1  Investigate the structure of the birds dataset.\n  Solution (click here)  glimpse(birds) #\u0026gt; Rows: 311,441 #\u0026gt; Columns: 12 #\u0026gt; $ class \u0026lt;chr\u0026gt; \"Aves\", \"Aves\", \"Aves\", \"Aves\", \"Aves\", \"Aves\", \"Ave… #\u0026gt; $ order \u0026lt;chr\u0026gt; \"Passeriformes\", \"Passeriformes\", \"Passeriformes\", \"… #\u0026gt; $ family \u0026lt;chr\u0026gt; \"Corvidae\", \"Corvidae\", \"Corvidae\", \"Corvidae\", \"Cor… #\u0026gt; $ genus \u0026lt;chr\u0026gt; \"Cyanocitta\", \"Cyanocitta\", \"Cyanocitta\", \"Cyanocitt… #\u0026gt; $ species \u0026lt;chr\u0026gt; \"Cyanocitta cristata\", \"Cyanocitta cristata\", \"Cyano… #\u0026gt; $ locality \u0026lt;chr\u0026gt; \"44805 Ashland\", \"45244 Cincinnati\", \"44132 Euclid\",… #\u0026gt; $ stateProvince \u0026lt;chr\u0026gt; \"Ohio\", \"Ohio\", \"Ohio\", \"Ohio\", \"Ohio\", \"Ohio\", \"Ohi… #\u0026gt; $ decimalLatitude \u0026lt;dbl\u0026gt; 40.86166, 39.10666, 41.60768, 39.24236, 39.28207, 41… #\u0026gt; $ decimalLongitude \u0026lt;dbl\u0026gt; -82.31558, -84.32972, -81.50085, -84.35545, -84.4688… #\u0026gt; $ eventDate \u0026lt;dttm\u0026gt; 2007-02-16, 2007-02-17, 2007-02-17, 2007-02-19, 200… #\u0026gt; $ species_en \u0026lt;chr\u0026gt; \"Blue Jay\", \"Blue Jay\", \"Blue Jay\", \"Blue Jay\", \"Blu… #\u0026gt; $ range \u0026lt;chr\u0026gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, …       Exercise 2  Create a new data frame that removes the column range.\n  Hints (click here)  \nTry using select(). Remember, you can tell select() what you want to keep, and what you want to remove.    Solutions (click here)  birds_no_range \u0026lt;- birds %\u0026gt;% select(-range) head(birds_no_range) #\u0026gt; # A tibble: 6 x 11 #\u0026gt; class order family genus species locality stateProvince decimalLatitude #\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;dbl\u0026gt; #\u0026gt; 1 Aves Pass… Corvi… Cyan… Cyanoc… 44805 A… Ohio 40.9 #\u0026gt; 2 Aves Pass… Corvi… Cyan… Cyanoc… 45244 C… Ohio 39.1 #\u0026gt; 3 Aves Pass… Corvi… Cyan… Cyanoc… 44132 E… Ohio 41.6 #\u0026gt; 4 Aves Pass… Corvi… Cyan… Cyanoc… 45242 C… Ohio 39.2 #\u0026gt; 5 Aves Pass… Corvi… Cyan… Cyanoc… 45246 C… Ohio 39.3 #\u0026gt; 6 Aves Pass… Corvi… Cyan… Cyanoc… 44484 W… Ohio 41.2 #\u0026gt; # … with 3 more variables: decimalLongitude \u0026lt;dbl\u0026gt;, eventDate \u0026lt;dttm\u0026gt;, #\u0026gt; # species_en \u0026lt;chr\u0026gt;       Exercise 3  How many unique species of birds have been observed?.\n  Hints (click here)  Try using summarize() with a group_by() helper.    Solutions (click here)  # using a combo of group_by() and summarize() unique_birds \u0026lt;- birds %\u0026gt;% group_by(species_en) %\u0026gt;% summarize() #\u0026gt; `summarise()` ungrouping output (override with `.groups` argument) dim(unique_birds) # question - are there really 170 different birds observed? take a look at this summary #\u0026gt; [1] 170 1 # a one line, base R approach length(unique(birds$species_en)) #\u0026gt; [1] 170 # another base R approach using distinct() and nrow() birds %\u0026gt;% distinct(species_en) %\u0026gt;% # find distinct occurences nrow() # counts rows #\u0026gt; [1] 170 # using n_distinct() birds %\u0026gt;% summarize(n_distinct(species_en)) #\u0026gt; # A tibble: 1 x 1 #\u0026gt; `n_distinct(species_en)` #\u0026gt; \u0026lt;int\u0026gt; #\u0026gt; 1 170       Exercise 4  How many times have Bald Eagles been observed?.\n  Hints (click here)  Try using filter(). Remember the syntax you need to use to indicate you are looking for a Bald Eagle.    Solutions (click here)  birds_bald_eagle \u0026lt;- birds %\u0026gt;% filter(species_en == \"Bald Eagle\") dim(birds_bald_eagle) #\u0026gt; [1] 381 12       Exercise 5  How many times have any kind of eagle been observed?. Group hint: there are only Bald Eagle and Golden Eagle in this dataset.\n  Hints (click here)  There is a way to denote OR within filter().    More Hints (click here)  You denote OR by using the vertical bar.    Solutions (click here)  birds_alleagles \u0026lt;- birds %\u0026gt;% filter(species_en == \"Bald Eagle\" | species_en == \"Golden Eagle\") dim(birds_alleagles) #\u0026gt; [1] 386 12       Exercise 6  What is the northern most location of the bird observations in Ohio?\n  Hints (click here)  Try using arrange(). You can arrange in both ascending and descending order. You can also use your Ohio knowledge to check if you\u0026rsquo;ve done this correctly.    Solutions (click here)  birds_sort_lat \u0026lt;- birds %\u0026gt;% arrange(-decimalLatitude) head(birds_sort_lat) #\u0026gt; # A tibble: 6 x 12 #\u0026gt; class order family genus species locality stateProvince decimalLatitude #\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;dbl\u0026gt; #\u0026gt; 1 Aves Pass… Cardi… Card… Cardin… Conneaut Ohio 41.9 #\u0026gt; 2 Aves Pass… Ember… Zono… Zonotr… Conneaut Ohio 41.9 #\u0026gt; 3 Aves Colu… Colum… Zena… Zenaid… Conneaut Ohio 41.9 #\u0026gt; 4 Aves Pici… Picid… Dend… Dendro… Conneaut Ohio 41.9 #\u0026gt; 5 Aves Anse… Anati… Anas Anas p… Conneaut Ohio 41.9 #\u0026gt; 6 Aves Pass… Turdi… Sial… Sialia… Conneaut Ohio 41.9 #\u0026gt; # … with 4 more variables: decimalLongitude \u0026lt;dbl\u0026gt;, eventDate \u0026lt;dttm\u0026gt;, #\u0026gt; # species_en \u0026lt;chr\u0026gt;, range \u0026lt;chr\u0026gt;       Bonus time! Bonus 1  What is the most commonly observed bird in Ohio?\n  Hints (click here)  Try using tally() and a little helper term.\n   Solutions (click here)  unique_birds_tally \u0026lt;- birds %\u0026gt;% group_by(species_en) %\u0026gt;% tally(sort = TRUE) head(unique_birds_tally) #\u0026gt; # A tibble: 6 x 2 #\u0026gt; species_en n #\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;int\u0026gt; #\u0026gt; 1 Northern Cardinal 23064 #\u0026gt; 2 Mourning Dove 19135 #\u0026gt; 3 Dark-eyed Junco 18203 #\u0026gt; 4 Downy Woodpecker 17196 #\u0026gt; 5 House Sparrow 15939 #\u0026gt; 6 Blue Jay 15611 # another option birds %\u0026gt;% count(species_en, sort = TRUE) #\u0026gt; # A tibble: 170 x 2 #\u0026gt; species_en n #\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;int\u0026gt; #\u0026gt; 1 Northern Cardinal 23064 #\u0026gt; 2 Mourning Dove 19135 #\u0026gt; 3 Dark-eyed Junco 18203 #\u0026gt; 4 Downy Woodpecker 17196 #\u0026gt; 5 House Sparrow 15939 #\u0026gt; 6 Blue Jay 15611 #\u0026gt; 7 American Goldfinch 14732 #\u0026gt; 8 House Finch 14551 #\u0026gt; 9 Tufted Titmouse 14409 #\u0026gt; 10 Black-capped Chickadee 13471 #\u0026gt; # … with 160 more rows       Bonus 2  What is the least commonly observed bird (or birds) in Ohio?\n  Hints (click here)  Try using the data frame you\u0026rsquo;ve created in the previous exercise.    Solutions (click here)  unique_birds_tally %\u0026gt;% arrange(n) #\u0026gt; # A tibble: 170 x 2 #\u0026gt; species_en n #\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;int\u0026gt; #\u0026gt; 1 Arctic Redpoll 1 #\u0026gt; 2 Clay-colored Sparrow 1 #\u0026gt; 3 Dickcissel 1 #\u0026gt; 4 Eurasian Wigeon 1 #\u0026gt; 5 Great Egret 1 #\u0026gt; 6 Green Heron 1 #\u0026gt; 7 Grey Partridge 1 #\u0026gt; 8 Harris's Sparrow 1 #\u0026gt; 9 Lesser Yellowlegs 1 #\u0026gt; 10 Lincoln's Sparrow 1 #\u0026gt; # … with 160 more rows # or, if you knew the rarest was those observed only once  unique_birds_tally %\u0026gt;% filter(n == 1) #\u0026gt; # A tibble: 19 x 2 #\u0026gt; species_en n #\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;int\u0026gt; #\u0026gt; 1 Arctic Redpoll 1 #\u0026gt; 2 Clay-colored Sparrow 1 #\u0026gt; 3 Dickcissel 1 #\u0026gt; 4 Eurasian Wigeon 1 #\u0026gt; 5 Great Egret 1 #\u0026gt; 6 Green Heron 1 #\u0026gt; 7 Grey Partridge 1 #\u0026gt; 8 Harris's Sparrow 1 #\u0026gt; 9 Lesser Yellowlegs 1 #\u0026gt; 10 Lincoln's Sparrow 1 #\u0026gt; 11 Loggerhead Shrike 1 #\u0026gt; 12 Nelson's Sparrow 1 #\u0026gt; 13 Northern Rough-winged Swallow 1 #\u0026gt; 14 Orchard Oriole 1 #\u0026gt; 15 Prairie Falcon 1 #\u0026gt; 16 Red-throated Loon 1 #\u0026gt; 17 Ross's Goose 1 #\u0026gt; 18 Warbling Vireo 1 #\u0026gt; 19 Western Osprey 1       Bonus 3  In what year were the most Bald Eagles observed?\n  Hints (click here)  You may want to convert your date column to a more simplified year-only date. Check out the package lubridate.    Solutions (click here)  library(lubridate) #\u0026gt;  #\u0026gt; Attaching package: 'lubridate' #\u0026gt; The following objects are masked from 'package:base': #\u0026gt;  #\u0026gt; date, intersect, setdiff, union birds_bald_eagle_year \u0026lt;- birds_bald_eagle %\u0026gt;% mutate(year = year(eventDate)) %\u0026gt;% # year() takes a date and outputs only year group_by(year) %\u0026gt;% tally() arrange(birds_bald_eagle_year, -n) #\u0026gt; # A tibble: 11 x 2 #\u0026gt; year n #\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;int\u0026gt; #\u0026gt; 1 2008 81 #\u0026gt; 2 2006 66 #\u0026gt; 3 2009 58 #\u0026gt; 4 2007 40 #\u0026gt; 5 2005 30 #\u0026gt; 6 2004 26 #\u0026gt; 7 2000 23 #\u0026gt; 8 2001 23 #\u0026gt; 9 2003 15 #\u0026gt; 10 2002 14 #\u0026gt; 11 1999 5      \n","date":1606694400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1606593313,"objectID":"83eb9b3aa4eba14930c3c05a7e4ad0bc","permalink":"https://biodash.github.io/codeclub/02_dplyr-core-verbs/","publishdate":"2020-11-30T00:00:00Z","relpermalink":"/codeclub/02_dplyr-core-verbs/","section":"codeclub","summary":"During this second session of Code Club, we will be learning how to use some of the most popular dplyr one-table functions, including filter, select, mutate, arrange, and summarize.","tags":null,"title":"Session 2: dplyr core verbs","type":"codeclub"},{"authors":["Jelmer Poelstra"],"categories":[],"content":"\n Prep homework Basic computer setup If you didn\u0026rsquo;t already do this, please follow the Code Club Computer Setup instructions.\nTest if it works Please open RStudio locally or start an OSC RStudio Server session.\nNov 19 addition: If you\u0026rsquo;re working locally, test if you can load the tidyverse package with library(\u0026quot;tidyverse\u0026quot;) inside R. (If you haven\u0026rsquo;t installed the tidyverse yet, please go to the Code Club Computer Setup instructions.)\nIf you have not used RStudio before, take a moment to explore what\u0026rsquo;s in the panels and tabs. (It may help to check out Mike Sovic\u0026rsquo;s 1-minute intro to the RStudio interface or RStudio\u0026rsquo;s 3-minute intro.)\nIf you\u0026rsquo;re able to do so, please open RStudio again a bit before Code Club starts \u0026ndash; and in case you run into issues, please join the Zoom call early and we\u0026rsquo;ll troubleshoot.\nNew to R? If you\u0026rsquo;re completely new to R, it will be useful to have a look at some of the resources listed on our New to R? page prior to Code Club.\n Slides On Friday, we started with a couple of introductory slides.\n  1 - Create an RStudio Project Projects are an RStudio-specific concept that create a special file (.Rproj), primarily to designate a directory as the working directory for everything within it. We recommend creating exactly one separate Project for each research project with an R component \u0026ndash; and for things like Code Club.\n Why use Projects?\nIn brief, Projects help you to organize your work and to make it more portable.\n  They record which scripts (and R Markdown files) are open in RStudio, and will reopen all of those when you reopen the project. This becomes quite handy, say, when you work on three different projects, each of which uses a number of scripts.\n  When using Projects, you generally don\u0026rsquo;t have to manually set your working directory, and can use relative file paths to refer to files within the project. This way, even if you move the project directory, or copy it to a different computer, the same paths will still work. (This would not be the case if you used setwd() which will generally require you to use an absolute path, e.g. setwd(\u0026quot;C:/Users/Jelmer/Documents/\u0026quot;).)\n  Projects encourage you to organize research projects inside self-contained directories, rather than with files spread around your computer. This can save you a lot of headaches and increases reproducibility. And because R will restart whenever you switch Projects, there is no risk of unwanted cross-talk between your projects.\n    Let\u0026rsquo;s create an RStudio Project for Code Club:\n  Open RStudio locally or start an OSC RStudio Server session.\n(If you\u0026rsquo;re at OSC, you should see a file 0_CODECLUB.md that\u0026rsquo;s open in your top-left panel. You can ignore/close this file.)\n  If you\u0026rsquo;re working locally, create a directory wherever you like on your computer for all things Code Club. You can do this in R using dir.create(\u0026quot;path/to/your/dir\u0026quot;), or outside of R.\n(If you\u0026rsquo;re at OSC, skip this step because you\u0026rsquo;re automatically inside a Code Club-specific, personal directory.)\n  Click File (top menu bar) \u0026gt; New Project, and then select Existing Directory.\n  If you\u0026rsquo;re working locally, select the Code Club directory that you created in the previous step.\n  If you\u0026rsquo;re working at OSC, keep the default choice \u0026ldquo; ~\u0026rdquo; (i.e., home), which is the directory you started in when entering the RStudio Server session.\n    After RStudio automatically reloads, you should see the file ending in .Rproj in the RStudio Files tab in the lower right pane, and you will have the Project open. All done for now!\n  (For future Code Club sessions: RStudio will by default reopen the most recently used Project, and therefore, OSC users will have the Project automatically opened. If you\u0026rsquo;re working locally and are also using other Projects, you can open this Project with File \u0026gt; Open Project inside RStudio, or by clicking the .Rproj file in your file browser, which will open RStudio and the Project.)\n 2 - Orienting ourselves Where are we? We don\u0026rsquo;t need to set our working directory, because our newly created Project is open, and therefore, our working directory is the directory that contains the .Rproj file.\nTo see where you are, type or copy into the console (bottom left):\n# Print the working directory: getwd() # List the files in your current directory: dir() # This should print at least the `.RProj` file.   Create directories Create two new directories \u0026ndash; one for this session, and one for a dataset that we will download shortly (and will be reusing across sessions):\n# Dir for Code Club Session 1: dir.create(\"S01\") # Dir for our bird data: # (\"recursive\" to create two levels at once.) dir.create(\"data/birds/\", recursive = TRUE)   Create a script To keep a record of what we are doing, and to easily modify and rerun earlier commands, we\u0026rsquo;ll want to save our commands in a script and execute them from there, rather than typing our commands directly in the console.\n  Click File (top menu bar) \u0026gt; New File \u0026gt; R script.\n  Save the script (File \u0026gt; Save) as S01.R inside your S01 directory.\n  First line of the script We will now load the core set of 8 tidyverse packages all at once. To do so, type/copy the command below on the first line of the script, and then execute it by clicking Run (top right of script pane) or by pressing Ctrl Enter (Windows/Linux, this should also work in your browser) or ⌘ Enter (Mac).\n# If you're working locally, and did not install it yet: # install.packages(\"tidyverse\") # Load the tidyverse (meta)package: library(tidyverse) #\u0026gt; ── Attaching packages ─────────────────────────────────────── tidyverse 1.3.0 ── #\u0026gt; ✔ ggplot2 3.3.2 ✔ purrr  0.3.4 #\u0026gt; ✔ tibble  3.0.4 ✔ dplyr  1.0.2 #\u0026gt; ✔ tidyr  1.1.2 ✔ stringr 1.4.0 #\u0026gt; ✔ readr  1.3.1 ✔ forcats 0.5.0 #\u0026gt; ── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ── #\u0026gt; ✖ dplyr::filter() masks stats::filter() #\u0026gt; ✖ dplyr::lag() masks stats::lag()   If this worked, you should get the same output as shown in the code block above: it attached 8 packages, and it warns that some of its functions are now \u0026ldquo;masking\u0026rdquo; base R functions.\n The tidyverse is a very popular and useful ecosystem of R packages for data analysis, which we will be using a lot in Code Club.\nWhen we refer to \u0026ldquo;base R\u0026rdquo; as opposed to the tidyverse, we mean functions that are loaded in R by default (without loading a package), and that can perform similar operations in a different way.\n   3 - Getting our dataset We downloaded a Great Backyard Bird Count (GBBC) dataset from the Global Biodiversity Information Facility (GBIF). Because the file was 3.1 GB large, we selected only the records from Ohio and removed some uninformative columns. We also added columns with English names and the breeding range for each species. We\u0026rsquo;ll download the resulting much smaller file (41.5 MB) from our Github repo.\n The Great Backyard Bird Count The GBBC is an annual citizen science event where everyone is encouraged to to identify and count birds in their backyard \u0026ndash; or anywhere else \u0026ndash; for at least 15 minutes, and report their sightings online. Since 2013, it is a global event, but it has been organized in the US and Canada since 1998.\n  Download the data Let\u0026rsquo;s download the dataset using the download.file() function:\n# The URL to our file: birds_file_url \u0026lt;- \"https://raw.githubusercontent.com/biodash/biodash.github.io/master/assets/data/birds/backyard-birds_Ohio.tsv\" # The path to the file we want to download to: birds_file \u0026lt;- \"data/birds/backyard-birds_Ohio.tsv\" # Download: download.file(url = birds_file_url, destfile = birds_file)   Read the data Now, let\u0026rsquo;s read the file into R. The .tsv extension (\u0026ldquo;tab-separated values\u0026rdquo;) tells us this is a plain text file in which columns are separated by tabs, so we will use a convenience function from the readr package (which is loaded as part of the core set tidyverse packages) for exactly this type of file:\n# Read the data: birds \u0026lt;- read_tsv(file = birds_file) #\u0026gt; Parsed with column specification: #\u0026gt; cols( #\u0026gt; class = col_character(), #\u0026gt; order = col_character(), #\u0026gt; family = col_character(), #\u0026gt; genus = col_character(), #\u0026gt; species = col_character(), #\u0026gt; locality = col_character(), #\u0026gt; stateProvince = col_character(), #\u0026gt; decimalLatitude = col_double(), #\u0026gt; decimalLongitude = col_double(), #\u0026gt; eventDate = col_datetime(format = \"\"), #\u0026gt; species_en = col_character(), #\u0026gt; range = col_character() #\u0026gt; )   Done! We have now read our data into a tibble, which is a type of data frame (formally a data.frame): R\u0026rsquo;s object class to deal with tabular data wherein each column can contain a different type of data (numeric, characters/strings, etc).\n 4 - Exploring backyard birds Exercise 1 What\u0026rsquo;s in the dataset?\n  Explore the dataset using some functions and methods you may know to get a quick overview of data(frames), and try to understand what you see. What does a single row represent, and what is in each column? (Be sure to check out the hints below at some point, especially if you\u0026rsquo;re stuck.)\n  Pay attention to the data types (e.g., \u0026ldquo;character\u0026rdquo; or chr) of the different columns, which several of these functions print. The output of our read_tsv() command also printed this information \u0026ndash; this function parsed our columns as the types we see now. Were all the columns parsed correctly?\n  How many rows and how many columns does the dataset have?\n  What are some questions you would like to explore with this dataset? We\u0026rsquo;ll collect some of these and try to answer them in later sessions. If your group has sufficient R skills already, you are also welcome to go ahead and try to answer one or more of these questions.\n    Hints (click here)  # Type an object's name to print it to screen: birds # Same as above, but explicitly calling print(): print(birds) # For column-wise information (short for \"structure\"): str(birds) # tidyverse version of str(): glimpse(birds) # In RStudio, open object in a separate tab: View(birds)     Note that in R, dbl (for \u0026ldquo;double\u0026rdquo;) and num (for \u0026ldquo;numeric\u0026rdquo;) are both used, and almost interchangeably so, for floating point numbers. (Integers are a separate type that are simply called \u0026ldquo;integers\u0026rdquo; and abbreviated as int, but we have no integer columns in this dataset.)\n  read_tsv() parsed our date as a \u0026ldquo;date-time\u0026rdquo; (dttm or POSIXct for short), which contains both a date and a time. In our case, it looks like the time is always \u0026ldquo;00:00:00\u0026rdquo; and thus doesn\u0026rsquo;t provide any information.\n     Solutions (click here)  # Just printing the glimpse() output, # which will show the number of rows and columns: glimpse(birds) #\u0026gt; Rows: 311,441 #\u0026gt; Columns: 12 #\u0026gt; $ class \u0026lt;chr\u0026gt; \"Aves\", \"Aves\", \"Aves\", \"Aves\", \"Aves\", \"Aves\", \"Ave… #\u0026gt; $ order \u0026lt;chr\u0026gt; \"Passeriformes\", \"Passeriformes\", \"Passeriformes\", \"… #\u0026gt; $ family \u0026lt;chr\u0026gt; \"Corvidae\", \"Corvidae\", \"Corvidae\", \"Corvidae\", \"Cor… #\u0026gt; $ genus \u0026lt;chr\u0026gt; \"Cyanocitta\", \"Cyanocitta\", \"Cyanocitta\", \"Cyanocitt… #\u0026gt; $ species \u0026lt;chr\u0026gt; \"Cyanocitta cristata\", \"Cyanocitta cristata\", \"Cyano… #\u0026gt; $ locality \u0026lt;chr\u0026gt; \"44805 Ashland\", \"45244 Cincinnati\", \"44132 Euclid\",… #\u0026gt; $ stateProvince \u0026lt;chr\u0026gt; \"Ohio\", \"Ohio\", \"Ohio\", \"Ohio\", \"Ohio\", \"Ohio\", \"Ohi… #\u0026gt; $ decimalLatitude \u0026lt;dbl\u0026gt; 40.86166, 39.10666, 41.60768, 39.24236, 39.28207, 41… #\u0026gt; $ decimalLongitude \u0026lt;dbl\u0026gt; -82.31558, -84.32972, -81.50085, -84.35545, -84.4688… #\u0026gt; $ eventDate \u0026lt;dttm\u0026gt; 2007-02-16, 2007-02-17, 2007-02-17, 2007-02-19, 200… #\u0026gt; $ species_en \u0026lt;chr\u0026gt; \"Blue Jay\", \"Blue Jay\", \"Blue Jay\", \"Blue Jay\", \"Blu… #\u0026gt; $ range \u0026lt;chr\u0026gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, …   # You can also check the number of rows and columns directly using: dim(birds) # Will return the number of rows and columns #\u0026gt; [1] 311441 12 nrow(birds) # Will return the number of rows #\u0026gt; [1] 311441 ncol(birds) # Will return the number of columns #\u0026gt; [1] 12     \n  Bonus material If your breakout group is done with Exercise 1, you can have a look at the bonus material below which includes another exercise. You can also have a look at this as homework. Or not at all!\n readr options for challenging files Earlier, we successfully read in our file without specifying any arguments other than the file name to the read_tsv() function, i.e. with all the default options. It is not always this easy!\nSome options for more complex cases:\n  The more general counterpart of this function is read_delim(), which allows you to specify the delimiter using the sep argument, e.g. delim=\u0026quot;\\t\u0026quot; for tabs.\n  There are also arguments to these functions for when you need to skip lines, when you don\u0026rsquo;t have column headers, when you need to specify the column types of some or all the columns, and so forth \u0026ndash; see this example:\nmy_df \u0026lt;- read_delim( file = \"file.txt\", delim = \"\\t\", # Specify tab as delimiter col_names = FALSE, # First line is not a header skip = 3, # Skip the first three lines comment = \"#\", # Skip any line beginning with a \"#\" col_types = cols( # Specify column types col1 = col_character(), # ..We only need to specify columns for  col2 = col_double() # ..which we need non-automatic typing ) )       Exercise 2 (Optional) Read this file!\nTry to read the following file into R, which is a modified and much smaller version of the bird dataset.\nMake the function parse the \u0026ldquo;order\u0026rdquo; column as a factor, and the \u0026ldquo;year\u0026rdquo;, \u0026ldquo;month\u0026rdquo;, and \u0026ldquo;day\u0026rdquo; columns as whatever you think is sensible.\n# Download and read the file: birds2_file_url \u0026lt;- \"https://raw.githubusercontent.com/biodash/biodash.github.io/master/assets/data/birds/backyard-birds_read-challenge.txt\" birds2_file \u0026lt;- \"data/birds/backyard-birds_read-challenge.txt\" download.file(url = birds2_file_url, destfile = birds2_file)   # Your turn! birds2 \u0026lt;- read_ # Complete the command     Hints (click here)    The file is saved as .txt, so the delimiter is not obvious \u0026ndash; first have a look at it (open it in RStudio, a text editor, or the terminal) to determine the delimiter. Then, use read_delim() with manual specification of the delimiter using the delim argument, or use a specialized convenience function.\n  Besides a leading line with no data, there is another problematic line further down. You will need both the skip and comment arguments to circumvent these.\n  Note that readr erroneously parses month as a character column if you don\u0026rsquo;t manually specify its type.\n  Note that you can also use a succinct column type specification like col_types = \u0026quot;fc\u0026quot;, which would parse, for a two-column file, the first column as a factor and the second as a character \u0026ndash; type e.g. ?read_tsv for details.\n     Bare solution (click here)  # With succint column type specification: birds2 \u0026lt;- read_csv( file = birds2_file, skip = 1, comment = \"$\", col_types = \"fcdiii\" ) # With long column type specification: birds2 \u0026lt;- read_csv( file = birds2_file, skip = 1, comment = \"$\", col_types = cols( order = col_factor(), year = col_integer(), month = col_integer(), day = col_integer() ) )      Solution with explanations (click here)  # With succinct column type specification: birds2 \u0026lt;- read_csv( # `read_csv()`: file is comma-delimited file = birds2_file, skip = 1, # First line is not part of the dataframe comment = \"$\", # Line 228 is a comment that starts with `$` col_types = \"fcdiii\" # \"f\" for factor, \"c\" for character, ) # ..\"d\" for double (=numeric), # ..\"i\" for integer. # With long column type specification: birds2 \u0026lt;- read_csv( file = birds2_file, skip = 1, comment = \"$\", col_types = cols( # We can omit columns for which we order = col_factor(), # ..accept the automatic parsing, year = col_integer(), # ..when using the long specification.  month = col_integer(), day = col_integer() ) )      Other options for reading tabular data There are also functions in base R that read tabular data, such as read.table() and read.delim().\nThese are generally slower than the readr functions, and have less sensible default options to their arguments. Particularly relevant is how columns with characters (strings) are parsed \u0026ndash; until R 4.0, which was released earlier this year, base R\u0026rsquo;s default behavior was to parse them as factors, and this is generally not desirable1. readr functions will never convert columns with strings to factors.\nIf speed is important, such as when reading in very large files (~ 100s of MBs or larger), you should consider using the fread() function from the data.table package.\nFinally, some examples of reading other types of files:\n Read excel files directly using the readxl package. Read Google Sheets directly from the web using the googlesheets4 package. Read non-tabular data using the base R readLines() function.    \n  You can check which version of R you are running by typing sessionInfo(). You can also check directly how strings are read by default with default.stringsAsFactors(). To avoid conversion to factors, specify stringsAsFactors = FALSE in your read.table() / read.delim() function call. \u0026#x21a9;\u0026#xfe0e;\n   ","date":1604448000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1605969915,"objectID":"5b8cbf273e25c833a3e7f4cd2615654b","permalink":"https://biodash.github.io/codeclub/01_backyard-birds/","publishdate":"2020-11-04T00:00:00Z","relpermalink":"/codeclub/01_backyard-birds/","section":"codeclub","summary":"In the first session of Code Club, we'll make sure that everyone is properly set up, create an RStudio Project, and start working with some data from the Great Backyard Bird Count.","tags":["codeclub","backyard-birds"],"title":"Session 1: Backyard Birds","type":"codeclub"},{"authors":["Jelmer Poelstra","Mike Sovic","Stephen Opiyo","Michael Broe","Jessica Cooperstone"],"categories":[],"content":" Welcome to OSU Code Club! Materials for each episode will be provided in posts like this one, collected in the Code Club Sessions page.\n  For more information about OSU Code Club, and a form to sign up, see the About Code Club page.\n  For info on upcoming sessions, see here.\n  You can code locally or in your browser, see our page with computer setup instructions.\n  If you are completely new to R, see our page with resources and tips.\n  You can also suggest a topic to be covered at Code Club.\n   \n","date":1603065600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1604625794,"objectID":"fa58e17bb7648ba3c1d43d18ecb64a3a","permalink":"https://biodash.github.io/codeclub/00_welcome-to-codeclub/","publishdate":"2020-10-19T00:00:00Z","relpermalink":"/codeclub/00_welcome-to-codeclub/","section":"codeclub","summary":"Welcome to OSU Code Club! In this brief post, we point you to information related to Code Club on the website.","tags":["codeclub"],"title":"Welcome to Code Club","type":"codeclub"},{"authors":null,"categories":null,"content":"All material is released under a Creative Commons Attribution-ShareAlike 4.0 International License.\n   ","date":1578092400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1601687264,"objectID":"53e892b8b41cc4caece1cfd5ef21d6e7","permalink":"https://biodash.github.io/license/","publishdate":"2020-01-04T00:00:00+01:00","relpermalink":"/license/","section":"","summary":"All material is released under a Creative Commons Attribution-ShareAlike 4.0 International License.\n   ","tags":null,"title":"LICENSE: CC-BY-SA","type":"page"},{"authors":null,"categories":null,"content":"About BioDASH  The BioDASH website aims to assemble bioinformatic and computational training resources for researchers at The Ohio State University. It\u0026rsquo;s a joint initiative by bioinformaticians at OSU\u0026rsquo;s Molecular and Cellular Imaging Center (MCIC) - Computational Biology Lab, the Center for Applied Plant Sciences (CAPS), and the Department of Evolution, Ecology and Organismal Biology (EEOB).\nAs of fall 2020, this is still very much a work in progress, but more content will be added soon!\n Main Contributors    Jelmer Poelstra, MCIC Wooster\n   Mike Sovic, CAPS\n   Michael Broe, EEOB\n    \n ","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1605479556,"objectID":"8576ec274c98b3831668a172fa632d80","permalink":"https://biodash.github.io/about/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/about/","section":"","summary":"About BioDASH  The BioDASH website aims to assemble bioinformatic and computational training resources for researchers at The Ohio State University. It\u0026rsquo;s a joint initiative by bioinformaticians at OSU\u0026rsquo;s Molecular and Cellular Imaging Center (MCIC) - Computational Biology Lab, the Center for Applied Plant Sciences (CAPS), and the Department of Evolution, Ecology and Organismal Biology (EEOB).","tags":null,"title":"","type":"page"},{"authors":null,"categories":null,"content":"About OSU Code Club  OSU Code Club is a regularly occurring, interactive, online gathering to improve coding skills. We aim for a supportive and fun culture of learning together, and hope to offer something to participants at any experience level.\nIn each meeting, a presenter first introduces a concept or tool to be used for a challenge. Then, we work on the challenge in pairs or trios in Zoom \u0026ldquo;breakout rooms,\u0026rdquo; and finally, we reconvene to see what approaches were taken and to share lessons learned.\nThe idea for this Code Club was taken from a recent paper in PLoS Computational Biology: Ten simple rules to increase computational skills among biologists with Code Clubs. We liked this idea because of the high level of interaction and because gradual, well-spaced practice is an excellent way to retain what you learn.\nJoin us \u0026mdash; and perhaps present a session too! As the organizers, we are happy to present sessions, but we hope that as a participant, you will also want to do so.\nFor example, you could consult the group about an actual challenge you are facing in your data analysis. You could also introduce everyone to an new package or approach you\u0026rsquo;ve been using, or one that you are excited about and want to dive into \u0026ndash; teaching a topic can be one of the best ways to learn it!\n Practical information  In the first series, we will focus on all things R: from data analysis and visualization to efficient coding, R Markdown, and so on. There will be no consistent analysis type or data type \u0026mdash; instead, we will focus on building general skills and applying those to a wide variety of data. Each week, materials and suggested reading will be posted up front at the Sessions page. Like at a Journal Club, doing some preparatory homework by reading these materials will help you get the most out of it. Each session is intended to be mostly stand-alone to allow for occasional participation. To allow for a welcoming environment for participants at all levels of experience, we ask everyone to be respectful, patient, and collaborative when interacting at Code Club. This is not a competitive event. We have a separate page with computer setup instructions, where you\u0026rsquo;ll see that we also accommodate participating through your browser without any installations. We also have a form to suggest topics for Code Club!   Organizers   Jelmer Poelstra - bioinformatician at MCIC Wooster  Mike Sovic - bioinformatician at CAPS  Stephen Opiyo - biostatistician at MCIC Columbus  Michael Broe - bioinformatician at EEOB  Jessica Cooperstone - Asst. Professor at HCS \u0026amp; FST   Sign up To sign up, please fill out the Google Form below. Hope to see you at Code Club!\nLoading…   \n ","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1605227816,"objectID":"affd8a75456abca4d01de73213cffddb","permalink":"https://biodash.github.io/codeclub-about/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/codeclub-about/","section":"","summary":"About OSU Code Club  OSU Code Club is a regularly occurring, interactive, online gathering to improve coding skills. We aim for a supportive and fun culture of learning together, and hope to offer something to participants at any experience level.","tags":null,"title":"","type":"page"},{"authors":null,"categories":null,"content":"Code Club:  R \u0026ndash; Getting Started and Some Tips  New to R? If you are completely new to R, we recommend watching at least the first couple of videos from Mike Sovic\u0026rsquo;s Youtube playlist of short videos on R, and ideally all of them, prior to attending Code Club. Here is the first video:\n  In case you want to do more self-study (note that this is not required/needed), here are some additional resources:\n A useful and fun written tutorial is R for cats. For a more systematic and lengthy introduction to R, see A Tutorial Introduction to R (this gets fairly advanced after section 9). Excellent comprehensive introductions are the R Basics and Visualization classes by Rafael Irizarry that can be freely accessed; you do have to create an account.  Also, don\u0026rsquo;t hesitate to reach out to the Code Club organizers if you have any questions!\n Miscellaneous R tips Useful settings By default, R will try to save your \u0026ldquo;environment\u0026rdquo; (e.g., your loaded data, variables, etc) when you exit, and then reload everything the way it was upon restarting R. However, this is bad! You should always be able to reproduce your environment given a set of commands saved in an R script or R Markdown document, whereas saving and reloading your environment encourages you to be sloppy about this.\nTo disable this in RStudio, go to Tools \u0026gt; Global Options \u0026gt; General and set the options as follows:\n  Recommended R/RStudio settings   To start R in the same way from the command line:\nR --no-save --no-restore-data \n Installing R packages CRAN packages To install an R package that is available at CRAN, the default R package repository, from within R (e.g. in the R console in RStudio), use the install.packages() function.\nThe install.packages() function will handle dependencies within R \u0026ndash; i.e., it will install other R packages that your package depends on. Occasionally, when the install function needs to compile a package from source, errors arise that relate to missing system dependencies (i.e. software outside of R).\nOn Mac and Linux, these system dependencies are best installed outside of R, such as with homebrew on Mac or apt on Ubuntu. The errror message you got when trying to install an R package should tell you which system dependencies are needed.\nOn Windows, you can use the installr package to install such dependencies or other software from within R \u0026ndash; for example:\ninstall.packages(\u0026#34;installr\u0026#34;) # Install the installr package first installlr::install.RStudio() # Install RStudio installr::install.python() # Install Python \nSystem setup to installing packages \u0026ldquo;from source\u0026rdquo; Sometimes you need to install a package from source, that is, you need to compile the package rather than simply installing a pre-existing binary. (On Linux, where installing from source is often needed, this should work without additional steps.) On Windows and Mac, installing from source is generally only needed when you install a package from outside of CRAN (such as from Github, see below), but you will need to make sure you have the following non-R software:\nOn Windows, you will need Rtools ( Rtools installation instructions).\nOn a Mac, you will need Xcode (which can be installed from the Mac App store).\nYou can test whether or not you are able to install packages from source using the devtools package:\ninstall.packages(\u0026#34;devtools\u0026#34;) # Install the devtools package devtools::has_devel() # Check whether you can install packages from source For a bit more info, see this page.\nInstalling packages from Github To install a package from Github, use either the devtools or the remotes package \u0026ndash; for example:\ninstall.packages(\u0026#34;devtools\u0026#34;) # Install the devtools package devtools::install_github(\u0026#34;kbroman/broman\u0026#34;) # Install from a repository using \u0026#34;\u0026lt;username\u0026gt;/\u0026lt;repo-name\u0026gt;\u0026#34; This will install the package from source, so you will need to make sure you are able to do so by following the instructions in the section right above this one.\nInstalling packages from Bioconductor If you\u0026rsquo;re doing bioinformatic analyses in R, you will probably run into packages that are not on CRAN but on Bioconductor. To install a package from Bioconductor, use the BiocManager package \u0026ndash; for example:\ninstall.packages(\u0026#34;BiocManager\u0026#34;) # Install the BiocManager package BiocManager::install(\u0026#34;edgeR\u0026#34;) # Install the edgeR package from Bioconductor \nUpdating R Consider updating R if you have an older version of R installed. Specifically, in the first session of Code Club, we\u0026rsquo;ve seen problems when installing the tidyverse with R versions below R 3.6.\nYou can check which version of R you have by looking at the first lines of output when running the following command inside R:\nsessionInfo() To update:   Windows: You can update R from within R. The updateR() function will also take care of updating your packages:\ninstall.packages(\u0026#34;installr\u0026#34;) installr::updateR()   Mac: Download and install the latest .pkg file as if you were installing it for the first time.\n  Linux: In Ubuntu, if you installed R with apt or apt-get, you can use apt-get upgrade in a terminal. Otherwise, download and install the latest version after removing the old one. Rtask has some instructions for upgrading to R 4.0 in Ubuntu (along with upgrading to Ubuntu 20.04).\n  Re-installing your packages after updating (Mac and Linux) While the installr::updateR() function for Windows users takes care of reinstalling your packages along with updating R, Mac and Linux users will have to manually re-install their packages. Some people prefer to re-install these packages on the fly, which can end up being a way to get rid of packages you no longer use.\nBut if you want immediately reinstall all your packages, run this before you upgrade:\nmy_packages \u0026lt;- installed.packages() saveRDS(my_packages, \u0026#34;my_packages.rds\u0026#34;) Then, after you\u0026rsquo;ve installed the latest R version:\nmy_packages \u0026lt;- readRDS(\u0026#34;CurrentPackages.rds\u0026#34;) install.packages(my_packages[1, ]) This will only work for packages available on CRAN. Of course, you can check your list for Github-only and Bioconductor packages and then install those with their respective commands (see below). Yes, this can be a bit of a hassle!\n  \n ","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1606845019,"objectID":"ca094992cb695d0d14880a7b5e13427b","permalink":"https://biodash.github.io/codeclub-novice/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/codeclub-novice/","section":"","summary":"Code Club:  R \u0026ndash; Getting Started and Some Tips  New to R? If you are completely new to R, we recommend watching at least the first couple of videos from Mike Sovic\u0026rsquo;s Youtube playlist of short videos on R, and ideally all of them, prior to attending Code Club.","tags":null,"title":"","type":"page"},{"authors":null,"categories":null,"content":"Code Club:  Information for Presenters  Introduction   Each Code Club session should be represented by one post on the website at https://biodash.github.io/codeclub/.\n  Regular presenters will be given direct access to the Github repository and will be able to push a new post to the website directly.\n  Occasional presenters can either send their material directly to Jelmer or create a \u0026ldquo;pull request\u0026rdquo; with their new post.\n  Content should be written in R Markdown (.Rmd) or \u0026ldquo;plain\u0026rdquo; Markdown (.md). If you write in .Rmd, you need to render to .md locally. Conversion of .md to an HTML file suitable for the website will be done automatically upon pushing the master branch of the repository.\n  Make sure to get the session materials onto the website at least several days before the session.\n   Getting your files onto the site 1: Get the repo You only need to do this if you want to create a pull request or push your content to the website directly. If you want to send your (R) Markdown file by email, skip this and continue to Step 2.\nThe following assumes you have git installed, set up, have a Github account, and have your git linked up to Github.\nOption A: Fork the repo to prep for a Pull Request   Fork the repo: go to https://github.com/biodash/biodash.github.io and click the Fork button way in the top-right corner of the page.\n  Get the URL for your repo: In your forked repo, click the green Code button and copy the URL for the repo to your clipboard (either the HTTPS or the SSH URL; the former will be less likely to lead to authentication problems).\n  Go to a dir that you would like to be the parent dir of the Biodash/Codeclub repo:\ncd my-dir   Clone your forked repo, using the URL that you copied to your clipboard:\ngit clone https://github.com/\u0026lt;YOUR-USERNAME\u0026gt;/biodash.github.io.git   Move into the newly cloned (downloaded) repository dir:\ncd biodash.github.io   Add the original repository as an \u0026ldquo;upstream\u0026rdquo; remote:\ngit remote add upstream https://github.com/biodash/biodash.github.io.git  You can check which remote repos (i.e., repos on Github) are linked to your local repo using:\ngit remote -v This should show your forked repo as \u0026ldquo;origin\u0026rdquo;, and the original repo as \u0026ldquo;upstream\u0026rdquo;. You won\u0026rsquo;t be able to push to the original repo, but you can push to your forked repo and then submit a pull request, as we\u0026rsquo;ll do below.\n    Option B: Clone the repo directly (direct access required)   Go to a dir that you would like to be the parent dir of the Biodash/Codeclub repo:\ncd my-dir   Clone the website repo:\ngit clone https://github.com/biodash/biodash.github.io.git # Using HTTPS # Or: `git clone git@github.com:biodash/biodash.github.io.git` using SSH   Create a new branch (by way of example called \u0026ldquo;my-branch\u0026rdquo;) and switch to it:\ngit checkout -b my-branch Creating a new branch is not strictly necessary but it may be safer/easier to experiment in.\n   2: Create a Code Club post   Here, we\u0026rsquo;ll use the hugodown package to create a Markdown skeleton for our post, and below we\u0026rsquo;ll also use hugodown to preview the site.\nNote that you can easily bypass hugodown by simply copying the YAML header from the first code club session (see here for the .Rmd file) into a new file and taking it from there.  If you don\u0026rsquo;t have the hugodown package installed, install it:\nremotes::install_github(\u0026#34;r-lib/hugodown\u0026#34;) # Or equivalently, use devtools::install_githhub()   A post bundle is a separate folder for a post which will hold the R Markdown file that contains the post, as well as associated images and so on. To create a post bundle along with a R Markdown file that already has many useful YAML header tags:\nhugodown::use_post(\u0026#39;codeclub/\u0026lt;session-number\u0026gt;_\u0026lt;short-title\u0026gt;\u0026#39;) # An example would be: hugodown::use_post(\u0026#39;codeclub/01_intro-to-R\u0026#39;) The \u0026lt;session-number\u0026gt; is the actual Code Club session number, and \u0026lt;short-title\u0026gt; is a short title that you would like to give the post, which will be used for links and the folder name.\n The name of the .Rmd file will be index.Rmd, and it should keep that name! Keep this name also if you create your .Rmd manually or by copying the file from another Code Club session. It will eventually turn into index.html, which is the name that will trigger the file to be displayed on the website.     Fill out some of the YAML, such as the title, subtitle, authors (in kebab-case, e.g. john-doe, to link to your author profile; note that Jelmer\u0026rsquo;s name here is \u0026ldquo;admin\u0026rdquo;), and optionally tags and summary (the summary will appear on Biodash\u0026rsquo;s front page in the \u0026ldquo;Recent Posts\u0026rdquo; widget; this can be good to fill out here because the default summary can be awkward, as it combines headers and paragraphs).\n If you specify a date using the `date` tag in the YAML, and this date is in the future (e.g. the date of the Code Club session), the page will not be built and will thus not appear on the website! Specifiying the date using `date` or `lastmod` in the YAML is not particularly useful anyway -- when you edit the post after the specified date, it will use the edit date.     Write the contents of your Code Club session that you would like to share with participants, in R Markdown format. For formatting tips, see below.\n   If you want participants to load an R Markdown file or script:\nAn easy solution is to place the file in the same directory as your post, and include it in your git commit, so it will be uploaded to Github. In that case, the URL to the file for direct downloads for participants will be: https://raw.githubusercontent.com/biodash/biodash.github.io/master/docs/codeclub/\u0026lt;session-number\u0026gt;_\u0026lt;short-title\u0026gt;/\u0026lt;filename\u0026gt;.\nIn your post, include a function call like file.download(\u0026lt;script-URL\u0026gt;) for participants to get the file \u0026ndash; this will work both for participants working locally and those working in an OSC RStudio Server instance.\nIf your session contains a dataset:\nLike for the markdown/script, place the file(s) in the same directory as your post. If you have a markdown/script for participants, include file.download(\u0026lt;dataset-URL\u0026gt;) in this file, otherwise include it directly in your post.\n    Convert your .Rmd (R Markdown) file to a .md (Markdown) file.\n Hugo renders .md but not .Rmd to HTML, so we have to always render to .md first when writing in .Rmd.   Since your output is specified as hugodown::md_document, this is done most easily by \u0026ldquo;knitting\u0026rdquo; your post in RStudio by clicking Knit in the top bar, or by pressing Ctrl + Shift + K.\n   3: Preview your post or build the website (optional) You can do this in two ways, from RStudio or from the command line.\nOption A: In RStudio   Install Hugo:\nhugodown::hugo_install(\u0026#34;0.66.0\u0026#34;)   Preview the website:\nhugodown::hugo_start() #\u0026gt; Starting server on port 1313 This will provide a preview RStudio. To look at it in a browser, go to localhost:1313, where 1313 corresponds to the port returned in the R console (see above).\n  Option B: From the command line   Install Hugo using these instructions.\n  Serve the website locally:\nhugo serve You will see a message that includes \u0026ldquo;Web Server is available at [\u0026hellip;]\u0026rdquo;. Click the link or copy and paste the address into a browser, and you will see the rendered website.\nThe server will keep running and will update whenever you save changes in a file that is within the website directory, until you stop it using Ctrl + C.\n   Side note: Building the website Note that you don\u0026rsquo;t need to build the website, because it will be built automatically from Markdown files whenever you push to (the master branch of) the Github repo.\nBut as background info, or in case automatic builds fail, here is how you would build the site:\n  Using Hugo from the shell:\nhugo -d docs/   Using hugodown in R:\nhugodown::hugo_build(dest = \u0026#34;docs\u0026#34;)   The entire rendered website is in the docs/ dir; HTML files rendered from Markdown files will be placed there, any images and other files will be copied there, and so on.\n   4: Commit   Add the files from your post:\ngit add codeclub/\u0026lt;your-post-name\u0026gt;/* ## Or, e.g. if you added files elswehere too, or have built the site: # git add *   Check if all your changes and new files have been staged:\ngit status   Commit:\ngit commit -m \u0026#34;Add CodeClub session \u0026lt;session-nr\u0026gt; by \u0026lt;your-name\u0026gt;\u0026#34;    5: Push or submit pull request Your Markdown (.md) file(s) will be built along with the rest of the website by Hugo. Using Github Actions, this will be done automatically upon pushing to the master branch on Github, which is all we need to do. Note that the built website will be committed by Github Actions not to the master branch but to the gh-actions branch.\nOption A: Create a pull request When you create a pull request, you are asking the maintainers of a repository to pull your changes into their repository.\n  Pull from the original repo to make sure your repo is up-to-date:\ngit pull upstream master # \u0026#34;upstream\u0026#34; refers to the original Github repo This will first fetch the upstream changes and then merge them into your local repo, thus keeping your local changes. If git does not manage to perform this merge automatically, which can happen if the same parts of the same files have been edited both locally and upstream, there will be a merge conflict which you will need to resolve manually.\n  Push to your forked repo:\ngit push origin master # \u0026#34;origin\u0026#34; refers to your forked Github repo   Create the pull request:\n Go to the Pull requests page of our repo at https://github.com/biodash/biodash.github.io/pulls. Click the green button on the right that says New pull request. Under the large Compare changes header, click Compare across forks. In the drop-down menu to the right of the arrow, select your fork. Enter a title (e.g. \u0026ldquo;New Post: Session 6\u0026quot;) and description (say a little more about the post) for the pull request. Click the green button Send pull request.    For a more detailed step-by-step of creating a pull request from a fork, see here.\nOption B: Push to the site repo (direct access required)   Merge your branch with the main (master) branch:\ngit checkout master # Move to the master branch prior to merging git merge my-branch # Merge into master (assuming your branch was named \u0026#34;my-branch\u0026#34;)   Push to the master branch:\ngit push origin master    6: Install packages at OSC (optional) Many R packages are already installed at OSC (nearly 200 for R 4.0.2), including the tidyverse. You can check which packages have been installed by typing, in an R session at OSC:\nlibrary() This will list packages by library, which should include two locations available to all OSC users (starting with /usr/local/R), your personal library, and the Code Club library (/fs/ess/PAS1838/CODECLUB/Rpkgs).\nIf you want to make another package available to Code Club participants, you can do so as follows in an RStudio Server session at OSC:\ninstall.packages(\u0026#34;\u0026lt;pkg-name\u0026gt;\u0026#34;, lib = \u0026#34;/fs/ess/PAS1838/CODECLUB/Rpkgs\u0026#34;) This library is available to all members of the Code Club OSC classroom project. To check specifically which packages are available in this library \u0026ndash; and whether your newly installed package has indeed been installed here, type:\nlibrary(lib.loc = \u0026#34;/fs/ess/PAS1838/CODECLUB/Rpkgs\u0026#34;) Alternatively, you can let participants working at OSC install the packages themselves, like participants that work locally will have to do.\n Formatting tips Miscellaneous   If you want a Table of Contents (TOC) for your file, add a line toc: true to the YAML (not indented, as it is not an option of the output format).\n  To add an image, put it in the same directory as the markdown file, and refer to it without prepending a path.\n  \u0026lt;br\u0026gt; will insert a line break, which can be useful to get more space between sections.\n  I add lines above each major section header using ---- (preceded by a \u0026lt;br\u0026gt;).\n  Add a line that reads source_extension: '.Rmd' (not indented) to your R Markdown, which will ensure that there is a link to the source document at the top of your post.\nEDIT: I have removed these source links for now. They were also visible in the \u0026ldquo;Recent Posts\u0026rdquo; widget on the home page, and some people clicked on that link rather than the website link. Then, they ended up on in the Github repo but didn\u0026rsquo;t even know they were in the wrong place since the contents of the post is present.\n  Hidden sections It can be useful to provide solutions to small challenges in the file, but to hide them by default. This can be done with a little HTML:\n\u0026lt;details\u0026gt; \u0026lt;summary\u0026gt; Solution (click here) \u0026lt;/summary\u0026gt; \u0026lt;br\u0026gt; ... Your solution - this can be a long section including a code block... ```{r} install.packages(\u0026quot;tidyverse\u0026quot;) ``` \u0026lt;/details\u0026gt; This is rendered as:\n  Solution (click here)  \u0026hellip; Your solution - this can be a long section including a code block\u0026hellip;\ninstall.packages(\u0026quot;tidyverse\u0026quot;)  Info/alert notes To produce boxes to draw attention to specific content, you can use two classes specific to the Hugo Academic Theme (now branded as \u0026ldquo;Wowchemy\u0026rdquo;).\n  alert-note for a blue box with an info symbol:\n\u0026lt;div class=\u0026quot;alert alert-note\u0026quot;\u0026gt; \u0026lt;div\u0026gt; This is an alert note. \u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt; Which is rendered as:\n This is an alert note.     alert-warning for a red box with a warning symbol:\n\u0026lt;div class=\u0026quot;alert alert-warning\u0026quot;\u0026gt; \u0026lt;div\u0026gt; This is an alert warning. \u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt; Which is rendered as:\n This is an alert warning.     I also added a custom class, puzzle:\n\u0026lt;div class=\u0026quot;alert puzzle\u0026quot;\u0026gt; \u0026lt;div\u0026gt; This is a puzzle div, for do-it-yourself challenges. \u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt;  This is a puzzle div, for do-it-yourself challenges.   Custom classes and other custom formatting can be written in CSS in the assets/scss/custom.scss file.\n  All of these classes can also be called using pandoc\u0026rsquo;s ::: notation when you\u0026rsquo;re writing in .Rmd (but not if you\u0026rsquo;re writing in .md), e.g.:\n:::puzzle This is a puzzle div, for do-it-yourself challenges. :::   Code highlighting  Code highlighting doesn't work with out of the box with .Rmd files. But it should be possible to get it to work, stay tuned!   Hugo supports the highlighting of specific lines of code using the syntax below in md documents:\n```r {hl_lines=[1,\u0026quot;3-4\u0026quot;]} library(\u0026quot;tidyverse\u0026quot;) weight_df %\u0026gt;% mutate(mean_weight = mean(weight)) %\u0026gt;% select(mean_weight, everything()) dim(weight_df) ``` library(\u0026#34;tidyverse\u0026#34;) weight_df %\u0026gt;% mutate(mean_weight = mean(weight)) %\u0026gt;% select(mean_weight, everything()) dim(weight_df) Shortcodes  Like code highlighting, shortcodes only work with .md files. The blogdown package has a shortcode() function to support them (see here), but hugodown does not support them.   Hugo shortcodes are little code snippets for specific content. Some of these are specific to Wowchemy, and others are available for any Hugo site.\nHighlight text You can highlight text as follows:\nHere is some {{\u0026lt; hl \u0026gt;}}highlighted text{{\u0026lt; /hl \u0026gt;}}. This will render as:\nHere is some highlighted text.\nIcons Wowchemy supports shortcodes for icons, for instance:\n {{\u0026lt; icon name=\u0026#34;r-project\u0026#34; pack=\u0026#34;fab\u0026#34; \u0026gt;}}   {{\u0026lt; icon name=\u0026#34;python\u0026#34; pack=\u0026#34;fab\u0026#34; \u0026gt;}}   {{\u0026lt; icon name=\u0026#34;terminal\u0026#34; pack=\u0026#34;fas\u0026#34; \u0026gt;}} General Hugo shortcodes   To embed a Youtube video, use the following, replacing \u0026ldquo;videoID\u0026rdquo; by the actual ID (https://www.youtube.com/watch?v=ID) in\n{{\u0026lt; youtube ID \u0026gt;}}   To embed a Tweet, use the following, replacing \u0026ldquo;tweetID\u0026rdquo; by the actual ID (https://twitter.com/user/status/ID):\n{{\u0026lt; tweet ID \u0026gt;}}   For more info and more shortcodes, see the Hugo documentation on shortcodes.\n   \n","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1606671808,"objectID":"d2a87fb5a2b4f8e331f2a7033b4ca3df","permalink":"https://biodash.github.io/codeclub-present/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/codeclub-present/","section":"","summary":"Code Club:  Information for Presenters  Introduction   Each Code Club session should be represented by one post on the website at https://biodash.github.io/codeclub/.\n  Regular presenters will be given direct access to the Github repository and will be able to push a new post to the website directly.","tags":null,"title":"","type":"page"},{"authors":null,"categories":null,"content":"Code Club:  Schedule  For Nov/Dec 2020, we will do each session twice: Wednesdays at 5 pm and Fridays at 3 pm. Please attend whichever one works better for you!\nBefore you attend for the first time, make sure to have a look at the Computer Setup page, and especially if you\u0026rsquo;re new to R, at the Getting Started with R page.\nHere are the dates for the first four sessions:\n   Session nr. Wed 5 pm Fri 3 pm Presenter Topic (+ link) Other     1 Nov 18 Nov 20 Jelmer  RStudio Projects \u0026amp; getting started  slides   2 Dec 2 Dec 4 Jessica dplyr core verbs    3 Dec 9 Dec 11 Mike S. TBD    4 Dec 16 Dec 18 Michael B. TBD     See also the BioDASH calendar for an overview.\nDates and times for sessions during the Spring semester will be determined in December.\n   \n ","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1605974177,"objectID":"21036bb90326781dbc3f5f76a5396fb3","permalink":"https://biodash.github.io/codeclub-schedule/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/codeclub-schedule/","section":"","summary":"Code Club:  Schedule  For Nov/Dec 2020, we will do each session twice: Wednesdays at 5 pm and Fridays at 3 pm. Please attend whichever one works better for you!","tags":null,"title":"","type":"page"},{"authors":null,"categories":null,"content":"Code Club:  Computer Setup  Here, you will find general information on computer setup for Code Club. Additional setup instructions for individual sessions will appear in the posts for each session.\nSummary:  You can work locally or at at the Ohio Supercomputer Center (OSC) in your browser. If you plan to work at OSC:  Sign up at OSC if you don\u0026rsquo;t have an account yet. You should have received Test if you can start an RStudio Server session.   If you plan to work locally:   Install R and install RStudio, or update R if your version is below R 3.6.  Install the tidyverse and test if you can load it. We recommend you do make sure you have an active OSC account with access to the Code Club project, as a backup option.   Have a look at the  introductory slides if you missed the first session. See the  Getting Started with R page if you have little experience with R. If you have not used RStudio before, take a moment to explore it, and it may help to check out Mike Sovic\u0026rsquo;s 1-minute intro or RStudio\u0026rsquo;s intro video.   Option 1 \u0026ndash; OSC All Code Club participants will get access to the Ohio Supercomputer Center (OSC) Classroom Project for Code Club (PAS1838). This way, you can code in (e.g.) RStudio from your browser rather than with a local installation. This is a good option if you prefer not to install anything locally or run into problems when doing so.\nIf you already had an OSC account, you should have been added to the Code Club OSC project and can continue to the second step. Otherwise, please follow the instructions below to sign up and get access to the project.\nSign up at OSC To sign up:\n  Go to https://my.osc.edu/ and click the blue \u0026ldquo;Sign Up\u0026rdquo; bar.\n  In the bottom right portion of the form where you provide your info (see screenshot below), you should enter Code Club\u0026rsquo;s Project Code, which is PAS1838. If you want to use OSC, please do this on a day prior to your first Code Club participation. This way, there is time to troubleshoot if needed. Moreover, the Code Club option on the Interactive Apps page below can take a few hours to appear after you become a member of the project.\n    Enter Project Code PAS1838 in the red box (click to enlarge)   Run RStudio Server during Code Club  OSC OnDemand lets you access OSC resources through your browser and run a couple of applications with GUIs, like RStudio. It has a separate access point, https://class.osc.edu/, for classroom projects such as this one.\n To get started, go to https://class.osc.edu/ and log in with your OSC username and password. Then, click on Interactive Apps in the blue top bar, and select RStudio Server (Owens and Pitzer): Form. Now, you\u0026rsquo;re on a page from which you can launch an RStudio server that will run on an OSC cluster.  Under Class Materials, select Code Club. Under Number of hours, enter 2. Click Launch.   Now, you should see a box like this:    Your job should start running pretty soon, and when it\u0026rsquo;s ready the box should look like this:    Click Connect to RStudio Server at the bottom of the box, and an RStudio Server instance will open. You\u0026rsquo;re ready to go!  More about OSC The above instructions should be all you need to access RStudio using OSC, but there is lot more to OSC than that! For more information about using OSC, see the excellent Getting Started materials on their website (make sure not to miss the HOWTOs). Also, Mike Sovic has a YouTube playlist \u0026ldquo;Getting Started With High Performance Computing (HPC)\u0026quot; at his channel The Data Point.\n Option 2 \u0026ndash; Local install Summary You will need:\n R: At least version 3.6 \u0026ndash; See here for instructions to update R RStudio R packages that we will regularly use:  tidyverse    Install R  Windows: Download and run the .exe file for the latest version of R from https://cran.r-project.org/bin/windows/base/, by clicking the large Download R [version-number] for Windows link at the top of the gray box. Mac: Download and run the .pkg file for the latest version of R from https://cran.r-project.org/bin/macosx/, by clicking the link just below Latest release. On a Linux distribution, you can also install R using the website above, but you may prefer to use a package manager instead \u0026ndash; for instance, seee these instructions for installing the latest R version on Ubuntu 20.04 using the apt package manager.  Install RStudio RStudio is a so-called Integrated Development Environment (IDE) for R, with side-by-side panes for an R script, an R concole, plots, help documents, and much more. While it is perfectly possible to use R without RStudio, RStudio has become the de facto standard for working with R and is very useful.\nTo install RStudio, go to the RStudio download page and download and run the installer file for your operating system.\nInstall the tidyverse Install the tidyverse, which is a collection of useful R packages, by typing the following command inside an R console:\ninstall.packages(\u0026#34;tidyverse\u0026#34;) Test whether you can load the tidyverse When you issue the command library(\u0026quot;tidyverse\u0026quot;), you should get the output shown below:\nlibrary(\u0026#34;tidyverse\u0026#34;) #\u0026gt; ── Attaching packages ─────────────────────────────────────── tidyverse 1.3.0 ── #\u0026gt; ✔ ggplot2 3.3.2 ✔ purrr 0.3.4 #\u0026gt; ✔ tibble 3.0.4 ✔ dplyr 1.0.2 #\u0026gt; ✔ tidyr 1.1.2 ✔ stringr 1.4.0 #\u0026gt; ✔ readr 1.3.1 ✔ forcats 0.5.0 #\u0026gt; ── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ── #\u0026gt; ✖ dplyr::filter() masks stats::filter() #\u0026gt; ✖ dplyr::lag() masks stats::lag() If you get an error instead, please try to troubleshoot it. Updating R itself may be necessary, see here for instructions. You can also send the organizers of Code Club an email. And if you can\u0026rsquo;t get it to work yet, you can always use OSC for the time being, see the setup instructions further up on this page.\n More info Please see the  Getting started with R page for:\n  Resources to get started with R  Useful R and RStudio settings  The basics of installing packages in R  Instructions for updating R    \n ","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1606343049,"objectID":"a19fd71e3dc86af820a45dabc994dda5","permalink":"https://biodash.github.io/codeclub-setup/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/codeclub-setup/","section":"","summary":"Code Club:  Computer Setup  Here, you will find general information on computer setup for Code Club. Additional setup instructions for individual sessions will appear in the posts for each session.","tags":null,"title":"","type":"page"},{"authors":null,"categories":null,"content":"Code Club:  Suggest a Topic!  Please use the form below to suggest a topic or concept to be covered at Code Club. You are also welcome to leave a suggestion relating to the general format, organization, or presentation of Code Club.\nIf you suggest a topic, a broad range of suggestions are welcome \u0026ndash; it need not fit neatly as a single Code Club session. So your suggestion can be as broad as \u0026ldquo;object-oriented programming\u0026rdquo; or as specific as a single R function that you happen to struggle with or that you just really like.\nWe do note that we prefer to cover topics that could be \u0026ndash;at least in principle\u0026ndash; of interest to a broad range of people, and are not specific to a certain data type. For instance, we would generally be hesitant to cover in detail the high-level functions of an R package to analyze microbiomic data.\nLoading…   \n ","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"aa47a17260af4b87dc29397d821ae7fd","permalink":"https://biodash.github.io/codeclub-suggest/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/codeclub-suggest/","section":"","summary":"Code Club:  Suggest a Topic!  Please use the form below to suggest a topic or concept to be covered at Code Club. You are also welcome to leave a suggestion relating to the general format, organization, or presentation of Code Club.","tags":null,"title":"","type":"page"},{"authors":null,"categories":null,"content":"Other Events  On this page, we will list upcoming events related to computational biology, coding, and data analysis. If you know of an event that you think should be listed here, please use the form in the Suggest\u0026hellip; page.\n Calendar   Recurring Events  CAPS Tn-seq working group  A working group dedicated to the analysis of Transposon-seq (Tn-seq) data. Every Monday from 10-11 am. Contact Mike Sovic for details.     MCIC bioinformatics office hour  Need some quick advice or help? Drop by! Every Tuesday from 2-4 pm: Zoom link. Advance notice to Jelmer Poelstra is appreciated. Anyone at OSU is welcome, and if you\u0026rsquo;re outside of OSU, feel free to inquire.     Center of Microbiome Center working groups  CoMS is running Virome, Microbiome, and Advanced Ecological Statistics working groups, see their page for more details.     Spring \u0026lsquo;21 Course: Practical Computing Skills for Biologists Jelmer Poelstra will teach a computing course as a section of PlantPath 8300 in the \u0026lsquo;21 spring semester.\n Focused on the command line, bash and Python scripting, and reproducible science with version control and automated workflows. 14 weeks, 2 credits, online-only Zoom sessions on Tuesdays and Thursdays from 3:55-4:55 pm. Graduate level, but undergraduates may be eligible to take the course as an IS. Sign up for class number 35953. Contact Jelmer for more information and a syllabus.   Upcoming Workshops None right now!\n Upcoming Outside of OSU  For Ohio Supercomputer Center events, such as regular introductory sessions to computing at OSC, see the OSC Events page.   Misc. Relevant OSU Courses   M5161: Introduction to Computational Genomics  M8161: Microbiome Informatics  PLNTPTH 7003.01: Agricultural Genomics: Principles and Applications  HCS 7806: Current Topics and Methods Courses  Includes \u0026ldquo;Genome Analytics\u0026rdquo; and \u0026ldquo;Methods in Data Visualization\u0026rdquo;.    ENR8600: Introduction to R for Environmental Sciences  MOLGEN 5645: Quantitative, Population, and Evolutionary Genetics  MOLGEN 5623: Genetics and Genomics  STAT 6625: Statistical Analysis of Genetic Data  STAT 6730: Introduction to Computational Statistics  FDSCTE 7600: Metabolomics, Principles and Practice   Past Events TBA\n  \n ","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1605226921,"objectID":"426d522fcb82973f95d828bcc08f03ff","permalink":"https://biodash.github.io/events/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/events/","section":"","summary":"Other Events  On this page, we will list upcoming events related to computational biology, coding, and data analysis. If you know of an event that you think should be listed here, please use the form in the Suggest\u0026hellip; page.","tags":null,"title":"","type":"page"},{"authors":null,"categories":null,"content":"Material  Here, we will post tutorials, analysis pipelines, instructional videos, slidedecks, materials from past workshops, and so on.\nStay tuned!\nFor now, have a look at the MCIC/MCBL\u0026rsquo;s Read-the-Docs site and at CAPS/Mike Sovic\u0026rsquo;s Youtube Channel.\n  \n ","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1605479556,"objectID":"4f38a30d7b59cc95eec7edb025f56bf6","permalink":"https://biodash.github.io/material/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/material/","section":"","summary":"Material  Here, we will post tutorials, analysis pipelines, instructional videos, slidedecks, materials from past workshops, and so on.\nStay tuned!\nFor now, have a look at the MCIC/MCBL\u0026rsquo;s Read-the-Docs site and at CAPS/Mike Sovic\u0026rsquo;s Youtube Channel.","tags":null,"title":"","type":"page"},{"authors":null,"categories":null,"content":"Suggest a topic or event  If there is a topic you would like to see covered on this website, an event you would like to see happen, or an event you think should be listed under Events, please fill out the form below. You can also indicate whether you would like to help with this content or event!\nLoading…   \n ","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1605479556,"objectID":"ec134bd5815c50401fba8e9a987eda12","permalink":"https://biodash.github.io/suggest/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/suggest/","section":"","summary":"Suggest a topic or event  If there is a topic you would like to see covered on this website, an event you would like to see happen, or an event you think should be listed under Events, please fill out the form below.","tags":null,"title":"","type":"page"},{"authors":null,"categories":null,"content":"Bioinformatics support  Available support Need assistance with bioinformatics, high-throughput sequencing data analysis, working with big data, etc? See below for a list of support options for OSU researchers\u0026hellip;\nMCIC The Molecular and Cellular Imaging Center (MCIC) is an OSU core facility with locations at the Wooster and Columbus campuses. Among other things, the MCIC provides end-to-end support for genomics projects \u0026mdash; from experimental design, library preparation, and sequencing, to infrastructure for and assistance with data analysis.\nThe bioinformatics section of the MCIC, the MCBL (MCIC Computational Biology Laboratory), works based on a membership model. MCBL members have access to bioinformatics support, our project at the Ohio Supercomputer Center for storage and computing, our two in-house servers, our computer lab in Wooster, and free access to workshops. To become a member, please fill out this form.\nFor bioinformatics consultation, anyone is free to contact Jelmer Poelstra or drop by at the Bioinformatics Office Hour over Zoom every Tuesday between 2 and 4 pm ( Zoom link - advance notice is appreciated!).\nCAPS The Center for Applied Plant Sciences (CAPS) supports OSU researchers working in the plant sciences. CAPS research scientist Mike Sovic leads bioinformatic support efforts for the Center. Details on opportunities and resources available through CAPS are at http://caps.osu.edu/bioinformatics.\nEEOB Research Scientist Michael Broe provides bioinformatics support to faculty and students in the Department of Evolution, Ecology and Organismal Biology. His primary role is to assist graduate students learning various types of computational analysis, but he also works directly with PIs. Types of analysis include whole genome assembly, genome annotation, transcriptomics, RADseq, hybrid capture pipelines, variant calling etc. Michael also teaches a 7 week Introduction to Computation in Biology for incoming EEOB graduate students each year, covering R, Python, and Unix.\n Request support Loading…   \n ","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1605742851,"objectID":"6f03e42d6bae7b75ea525bec87eb719f","permalink":"https://biodash.github.io/support/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/support/","section":"","summary":"Bioinformatics support  Available support Need assistance with bioinformatics, high-throughput sequencing data analysis, working with big data, etc? See below for a list of support options for OSU researchers\u0026hellip;\nMCIC The Molecular and Cellular Imaging Center (MCIC) is an OSU core facility with locations at the Wooster and Columbus campuses.","tags":null,"title":"","type":"page"}]